{"timestamp": "2025-07-18T17:06:38.356357", "cpu": {"percent": 37.6, "count": 10, "freq": {"current": 3228, "min": 600, "max": 3228}}, "memory": {"total_gb": 32.0, "used_gb": 11.04, "available_gb": 6.11, "percent": 80.9}, "disk": {"total_gb": 926.35, "used_gb": 18.97, "free_gb": 638.86, "percent": 2.05}, "gpu": {"available": true, "type": "Apple M1 Pro", "utilization_percent": 4.91, "memory_used_mb": null, "memory_total_mb": null}, "training_processes": [{"pid": 9769, "name": "full-line-inference", "cmdline": "/Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/full-line-inference.zip_extracted/full-line-inference.app/Contents/MacOS/full-line-inference --model /Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/flcc.model --type llama --beam-size 2 --iterations-count 20 --context-ratio 0.5 --min-cached 5 --max-missing 30 --max-model-ctx 0", "cpu_percent": 0, "memory_mb": 4.66}, {"pid": 55559, "name": "python3.13", "cmdline": "python huanhuan_train.py", "cpu_percent": 43.2, "memory_mb": 707.83}]}
{"timestamp": "2025-07-18T17:06:51.077017", "cpu": {"percent": 58.4, "count": 10, "freq": {"current": 3228, "min": 600, "max": 3228}}, "memory": {"total_gb": 32.0, "used_gb": 17.15, "available_gb": 2.38, "percent": 92.6}, "disk": {"total_gb": 926.35, "used_gb": 18.97, "free_gb": 630.86, "percent": 2.05}, "gpu": {"available": true, "type": "Apple M1 Pro", "utilization_percent": 62.43, "memory_used_mb": null, "memory_total_mb": null}, "training_processes": [{"pid": 9769, "name": "full-line-inference", "cmdline": "/Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/full-line-inference.zip_extracted/full-line-inference.app/Contents/MacOS/full-line-inference --model /Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/flcc.model --type llama --beam-size 2 --iterations-count 20 --context-ratio 0.5 --min-cached 5 --max-missing 30 --max-model-ctx 0", "cpu_percent": 0, "memory_mb": 4.2}, {"pid": 55559, "name": "python3.13", "cmdline": "python huanhuan_train.py", "cpu_percent": 31.0, "memory_mb": 90.0}]}
{"timestamp": "2025-07-18T17:07:00.400836", "cpu": {"percent": 48.0, "count": 10, "freq": {"current": 3228, "min": 600, "max": 3228}}, "memory": {"total_gb": 32.0, "used_gb": 22.31, "available_gb": 2.15, "percent": 93.3}, "disk": {"total_gb": 926.35, "used_gb": 18.97, "free_gb": 627.86, "percent": 2.05}, "gpu": {"available": true, "type": "Apple M1 Pro", "utilization_percent": 16.41, "memory_used_mb": null, "memory_total_mb": null}, "training_processes": [{"pid": 9769, "name": "full-line-inference", "cmdline": "/Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/full-line-inference.zip_extracted/full-line-inference.app/Contents/MacOS/full-line-inference --model /Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/flcc.model --type llama --beam-size 2 --iterations-count 20 --context-ratio 0.5 --min-cached 5 --max-missing 30 --max-model-ctx 0", "cpu_percent": 0, "memory_mb": 4.03}, {"pid": 55559, "name": "python3.13", "cmdline": "python huanhuan_train.py", "cpu_percent": 34.6, "memory_mb": 72.5}]}
{"timestamp": "2025-07-18T17:07:08.496274", "cpu": {"percent": 43.8, "count": 10, "freq": {"current": 3228, "min": 600, "max": 3228}}, "memory": {"total_gb": 32.0, "used_gb": 24.0, "available_gb": 2.03, "percent": 93.7}, "disk": {"total_gb": 926.35, "used_gb": 18.97, "free_gb": 626.86, "percent": 2.05}, "gpu": {"available": true, "type": "Apple M1 Pro", "utilization_percent": 91.79, "memory_used_mb": null, "memory_total_mb": null}, "training_processes": [{"pid": 9769, "name": "full-line-inference", "cmdline": "/Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/full-line-inference.zip_extracted/full-line-inference.app/Contents/MacOS/full-line-inference --model /Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/flcc.model --type llama --beam-size 2 --iterations-count 20 --context-ratio 0.5 --min-cached 5 --max-missing 30 --max-model-ctx 0", "cpu_percent": 0, "memory_mb": 4.03}, {"pid": 55559, "name": "python3.13", "cmdline": "python huanhuan_train.py", "cpu_percent": 32.4, "memory_mb": 82.7}]}
{"timestamp": "2025-07-18T17:07:16.869922", "cpu": {"percent": 51.4, "count": 10, "freq": {"current": 3228, "min": 600, "max": 3228}}, "memory": {"total_gb": 32.0, "used_gb": 21.62, "available_gb": 2.4, "percent": 92.5}, "disk": {"total_gb": 926.35, "used_gb": 18.97, "free_gb": 627.86, "percent": 2.05}, "gpu": {"available": true, "type": "Apple M1 Pro", "utilization_percent": 25.96, "memory_used_mb": null, "memory_total_mb": null}, "training_processes": [{"pid": 9769, "name": "full-line-inference", "cmdline": "/Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/full-line-inference.zip_extracted/full-line-inference.app/Contents/MacOS/full-line-inference --model /Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/flcc.model --type llama --beam-size 2 --iterations-count 20 --context-ratio 0.5 --min-cached 5 --max-missing 30 --max-model-ctx 0", "cpu_percent": 0, "memory_mb": 4.08}, {"pid": 55559, "name": "python3.13", "cmdline": "python huanhuan_train.py", "cpu_percent": 23.6, "memory_mb": 109.95}]}
{"timestamp": "2025-07-18T17:07:26.416778", "cpu": {"percent": 53.3, "count": 10, "freq": {"current": 3228, "min": 600, "max": 3228}}, "memory": {"total_gb": 32.0, "used_gb": 21.43, "available_gb": 2.82, "percent": 91.2}, "disk": {"total_gb": 926.35, "used_gb": 18.97, "free_gb": 626.86, "percent": 2.05}, "gpu": {"available": true, "type": "Apple M1 Pro", "utilization_percent": 7.34, "memory_used_mb": null, "memory_total_mb": null}, "training_processes": [{"pid": 9769, "name": "full-line-inference", "cmdline": "/Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/full-line-inference.zip_extracted/full-line-inference.app/Contents/MacOS/full-line-inference --model /Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/flcc.model --type llama --beam-size 2 --iterations-count 20 --context-ratio 0.5 --min-cached 5 --max-missing 30 --max-model-ctx 0", "cpu_percent": 0, "memory_mb": 4.08}, {"pid": 55559, "name": "python3.13", "cmdline": "python huanhuan_train.py", "cpu_percent": 22.1, "memory_mb": 68.73}]}
{"timestamp": "2025-07-18T17:07:34.979845", "cpu": {"percent": 56.3, "count": 10, "freq": {"current": 3228, "min": 600, "max": 3228}}, "memory": {"total_gb": 32.0, "used_gb": 16.22, "available_gb": 3.39, "percent": 89.4}, "disk": {"total_gb": 926.35, "used_gb": 18.97, "free_gb": 627.86, "percent": 2.05}, "gpu": {"available": true, "type": "Apple M1 Pro", "utilization_percent": 9.84, "memory_used_mb": null, "memory_total_mb": null}, "training_processes": [{"pid": 9769, "name": "full-line-inference", "cmdline": "/Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/full-line-inference.zip_extracted/full-line-inference.app/Contents/MacOS/full-line-inference --model /Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/flcc.model --type llama --beam-size 2 --iterations-count 20 --context-ratio 0.5 --min-cached 5 --max-missing 30 --max-model-ctx 0", "cpu_percent": 0, "memory_mb": 4.27}, {"pid": 55559, "name": "python3.13", "cmdline": "python huanhuan_train.py", "cpu_percent": 23.0, "memory_mb": 71.34}]}
{"timestamp": "2025-07-18T17:07:43.216351", "cpu": {"percent": 31.6, "count": 10, "freq": {"current": 3228, "min": 600, "max": 3228}}, "memory": {"total_gb": 32.0, "used_gb": 18.49, "available_gb": 4.25, "percent": 86.7}, "disk": {"total_gb": 926.35, "used_gb": 18.97, "free_gb": 627.86, "percent": 2.05}, "gpu": {"available": true, "type": "Apple M1 Pro", "utilization_percent": 43.13, "memory_used_mb": null, "memory_total_mb": null}, "training_processes": [{"pid": 9769, "name": "full-line-inference", "cmdline": "/Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/full-line-inference.zip_extracted/full-line-inference.app/Contents/MacOS/full-line-inference --model /Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/flcc.model --type llama --beam-size 2 --iterations-count 20 --context-ratio 0.5 --min-cached 5 --max-missing 30 --max-model-ctx 0", "cpu_percent": 0, "memory_mb": 4.27}, {"pid": 55559, "name": "python3.13", "cmdline": "python huanhuan_train.py", "cpu_percent": 33.9, "memory_mb": 90.08}]}
{"timestamp": "2025-07-18T17:07:51.367098", "cpu": {"percent": 66.3, "count": 10, "freq": {"current": 3228, "min": 600, "max": 3228}}, "memory": {"total_gb": 32.0, "used_gb": 22.47, "available_gb": 2.16, "percent": 93.3}, "disk": {"total_gb": 926.35, "used_gb": 18.97, "free_gb": 626.86, "percent": 2.05}, "gpu": {"available": true, "type": "Apple M1 Pro", "utilization_percent": 17.11, "memory_used_mb": null, "memory_total_mb": null}, "training_processes": [{"pid": 9769, "name": "full-line-inference", "cmdline": "/Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/full-line-inference.zip_extracted/full-line-inference.app/Contents/MacOS/full-line-inference --model /Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/flcc.model --type llama --beam-size 2 --iterations-count 20 --context-ratio 0.5 --min-cached 5 --max-missing 30 --max-model-ctx 0", "cpu_percent": 0, "memory_mb": 4.06}, {"pid": 55559, "name": "python3.13", "cmdline": "python huanhuan_train.py", "cpu_percent": 21.9, "memory_mb": 42.78}]}
{"timestamp": "2025-07-18T17:08:00.178649", "cpu": {"percent": 37.1, "count": 10, "freq": {"current": 3228, "min": 600, "max": 3228}}, "memory": {"total_gb": 32.0, "used_gb": 21.64, "available_gb": 2.49, "percent": 92.2}, "disk": {"total_gb": 926.35, "used_gb": 18.97, "free_gb": 627.87, "percent": 2.05}, "gpu": {"available": true, "type": "Apple M1 Pro", "utilization_percent": 75.37, "memory_used_mb": null, "memory_total_mb": null}, "training_processes": [{"pid": 9769, "name": "full-line-inference", "cmdline": "/Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/full-line-inference.zip_extracted/full-line-inference.app/Contents/MacOS/full-line-inference --model /Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/flcc.model --type llama --beam-size 2 --iterations-count 20 --context-ratio 0.5 --min-cached 5 --max-missing 30 --max-model-ctx 0", "cpu_percent": 0, "memory_mb": 4.03}, {"pid": 55559, "name": "python3.13", "cmdline": "python huanhuan_train.py", "cpu_percent": 34.5, "memory_mb": 121.19}]}
{"timestamp": "2025-07-18T17:08:08.112668", "cpu": {"percent": 46.3, "count": 10, "freq": {"current": 3228, "min": 600, "max": 3228}}, "memory": {"total_gb": 32.0, "used_gb": 22.3, "available_gb": 2.78, "percent": 91.3}, "disk": {"total_gb": 926.35, "used_gb": 18.97, "free_gb": 626.88, "percent": 2.05}, "gpu": {"available": true, "type": "Apple M1 Pro", "utilization_percent": 78.46, "memory_used_mb": null, "memory_total_mb": null}, "training_processes": [{"pid": 9769, "name": "full-line-inference", "cmdline": "/Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/full-line-inference.zip_extracted/full-line-inference.app/Contents/MacOS/full-line-inference --model /Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/flcc.model --type llama --beam-size 2 --iterations-count 20 --context-ratio 0.5 --min-cached 5 --max-missing 30 --max-model-ctx 0", "cpu_percent": 0, "memory_mb": 3.94}, {"pid": 55559, "name": "python3.13", "cmdline": "python huanhuan_train.py", "cpu_percent": 37.5, "memory_mb": 94.42}]}
{"timestamp": "2025-07-18T17:08:16.197245", "cpu": {"percent": 43.3, "count": 10, "freq": {"current": 3228, "min": 600, "max": 3228}}, "memory": {"total_gb": 32.0, "used_gb": 21.89, "available_gb": 2.32, "percent": 92.7}, "disk": {"total_gb": 926.35, "used_gb": 18.97, "free_gb": 626.88, "percent": 2.05}, "gpu": {"available": true, "type": "Apple M1 Pro", "utilization_percent": 43.26, "memory_used_mb": null, "memory_total_mb": null}, "training_processes": [{"pid": 9769, "name": "full-line-inference", "cmdline": "/Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/full-line-inference.zip_extracted/full-line-inference.app/Contents/MacOS/full-line-inference --model /Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/flcc.model --type llama --beam-size 2 --iterations-count 20 --context-ratio 0.5 --min-cached 5 --max-missing 30 --max-model-ctx 0", "cpu_percent": 0, "memory_mb": 4.08}, {"pid": 55559, "name": "python3.13", "cmdline": "python huanhuan_train.py", "cpu_percent": 29.0, "memory_mb": 84.83}]}
{"timestamp": "2025-07-18T17:08:25.239423", "cpu": {"percent": 42.3, "count": 10, "freq": {"current": 3228, "min": 600, "max": 3228}}, "memory": {"total_gb": 32.0, "used_gb": 18.12, "available_gb": 4.01, "percent": 87.5}, "disk": {"total_gb": 926.35, "used_gb": 18.97, "free_gb": 627.88, "percent": 2.05}, "gpu": {"available": true, "type": "Apple M1 Pro", "utilization_percent": 28.95, "memory_used_mb": null, "memory_total_mb": null}, "training_processes": [{"pid": 9769, "name": "full-line-inference", "cmdline": "/Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/full-line-inference.zip_extracted/full-line-inference.app/Contents/MacOS/full-line-inference --model /Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/flcc.model --type llama --beam-size 2 --iterations-count 20 --context-ratio 0.5 --min-cached 5 --max-missing 30 --max-model-ctx 0", "cpu_percent": 0, "memory_mb": 4.27}, {"pid": 55559, "name": "python3.13", "cmdline": "python huanhuan_train.py", "cpu_percent": 25.6, "memory_mb": 79.81}]}
{"timestamp": "2025-07-18T17:08:33.710118", "cpu": {"percent": 39.3, "count": 10, "freq": {"current": 3228, "min": 600, "max": 3228}}, "memory": {"total_gb": 32.0, "used_gb": 18.77, "available_gb": 4.73, "percent": 85.2}, "disk": {"total_gb": 926.35, "used_gb": 18.97, "free_gb": 626.88, "percent": 2.05}, "gpu": {"available": true, "type": "Apple M1 Pro", "utilization_percent": 33.27, "memory_used_mb": null, "memory_total_mb": null}, "training_processes": [{"pid": 9769, "name": "full-line-inference", "cmdline": "/Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/full-line-inference.zip_extracted/full-line-inference.app/Contents/MacOS/full-line-inference --model /Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/flcc.model --type llama --beam-size 2 --iterations-count 20 --context-ratio 0.5 --min-cached 5 --max-missing 30 --max-model-ctx 0", "cpu_percent": 0, "memory_mb": 4.27}, {"pid": 55559, "name": "python3.13", "cmdline": "python huanhuan_train.py", "cpu_percent": 35.1, "memory_mb": 74.62}]}
{"timestamp": "2025-07-18T17:08:41.816213", "cpu": {"percent": 43.5, "count": 10, "freq": {"current": 3228, "min": 600, "max": 3228}}, "memory": {"total_gb": 32.0, "used_gb": 21.56, "available_gb": 3.39, "percent": 89.4}, "disk": {"total_gb": 926.35, "used_gb": 18.97, "free_gb": 626.88, "percent": 2.05}, "gpu": {"available": true, "type": "Apple M1 Pro", "utilization_percent": 90.43, "memory_used_mb": null, "memory_total_mb": null}, "training_processes": [{"pid": 9769, "name": "full-line-inference", "cmdline": "/Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/full-line-inference.zip_extracted/full-line-inference.app/Contents/MacOS/full-line-inference --model /Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/flcc.model --type llama --beam-size 2 --iterations-count 20 --context-ratio 0.5 --min-cached 5 --max-missing 30 --max-model-ctx 0", "cpu_percent": 0, "memory_mb": 4.11}, {"pid": 55559, "name": "python3.13", "cmdline": "python huanhuan_train.py", "cpu_percent": 29.9, "memory_mb": 118.94}]}
{"timestamp": "2025-07-18T17:08:50.067773", "cpu": {"percent": 55.9, "count": 10, "freq": {"current": 3228, "min": 600, "max": 3228}}, "memory": {"total_gb": 32.0, "used_gb": 21.6, "available_gb": 2.43, "percent": 92.4}, "disk": {"total_gb": 926.35, "used_gb": 18.97, "free_gb": 626.88, "percent": 2.05}, "gpu": {"available": true, "type": "Apple M1 Pro", "utilization_percent": 78.83, "memory_used_mb": null, "memory_total_mb": null}, "training_processes": [{"pid": 9769, "name": "full-line-inference", "cmdline": "/Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/full-line-inference.zip_extracted/full-line-inference.app/Contents/MacOS/full-line-inference --model /Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/flcc.model --type llama --beam-size 2 --iterations-count 20 --context-ratio 0.5 --min-cached 5 --max-missing 30 --max-model-ctx 0", "cpu_percent": 0, "memory_mb": 4.08}, {"pid": 55559, "name": "python3.13", "cmdline": "python huanhuan_train.py", "cpu_percent": 34.4, "memory_mb": 85.59}]}
{"timestamp": "2025-07-18T17:08:58.217141", "cpu": {"percent": 55.5, "count": 10, "freq": {"current": 3228, "min": 600, "max": 3228}}, "memory": {"total_gb": 32.0, "used_gb": 18.23, "available_gb": 3.5, "percent": 89.1}, "disk": {"total_gb": 926.35, "used_gb": 18.97, "free_gb": 626.88, "percent": 2.05}, "gpu": {"available": true, "type": "Apple M1 Pro", "utilization_percent": 26.73, "memory_used_mb": null, "memory_total_mb": null}, "training_processes": [{"pid": 9769, "name": "full-line-inference", "cmdline": "/Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/full-line-inference.zip_extracted/full-line-inference.app/Contents/MacOS/full-line-inference --model /Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/flcc.model --type llama --beam-size 2 --iterations-count 20 --context-ratio 0.5 --min-cached 5 --max-missing 30 --max-model-ctx 0", "cpu_percent": 0, "memory_mb": 4.08}, {"pid": 55559, "name": "python3.13", "cmdline": "python huanhuan_train.py", "cpu_percent": 34.6, "memory_mb": 77.97}]}
{"timestamp": "2025-07-18T17:09:06.398741", "cpu": {"percent": 44.6, "count": 10, "freq": {"current": 3228, "min": 600, "max": 3228}}, "memory": {"total_gb": 32.0, "used_gb": 18.24, "available_gb": 4.82, "percent": 85.0}, "disk": {"total_gb": 926.35, "used_gb": 18.97, "free_gb": 626.89, "percent": 2.05}, "gpu": {"available": true, "type": "Apple M1 Pro", "utilization_percent": 21.72, "memory_used_mb": null, "memory_total_mb": null}, "training_processes": [{"pid": 9769, "name": "full-line-inference", "cmdline": "/Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/full-line-inference.zip_extracted/full-line-inference.app/Contents/MacOS/full-line-inference --model /Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/flcc.model --type llama --beam-size 2 --iterations-count 20 --context-ratio 0.5 --min-cached 5 --max-missing 30 --max-model-ctx 0", "cpu_percent": 0, "memory_mb": 4.25}, {"pid": 55559, "name": "python3.13", "cmdline": "python huanhuan_train.py", "cpu_percent": 36.8, "memory_mb": 61.19}]}
{"timestamp": "2025-07-18T17:09:14.574454", "cpu": {"percent": 68.7, "count": 10, "freq": {"current": 3228, "min": 600, "max": 3228}}, "memory": {"total_gb": 32.0, "used_gb": 17.25, "available_gb": 7.54, "percent": 76.4}, "disk": {"total_gb": 926.35, "used_gb": 18.97, "free_gb": 626.88, "percent": 2.05}, "gpu": {"available": true, "type": "Apple M1 Pro", "utilization_percent": 100.0, "memory_used_mb": null, "memory_total_mb": null}, "training_processes": [{"pid": 9769, "name": "full-line-inference", "cmdline": "/Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/full-line-inference.zip_extracted/full-line-inference.app/Contents/MacOS/full-line-inference --model /Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/flcc.model --type llama --beam-size 2 --iterations-count 20 --context-ratio 0.5 --min-cached 5 --max-missing 30 --max-model-ctx 0", "cpu_percent": 0, "memory_mb": 4.19}, {"pid": 55559, "name": "python3.13", "cmdline": "python huanhuan_train.py", "cpu_percent": 31.5, "memory_mb": 44.0}]}
{"timestamp": "2025-07-18T17:09:22.872567", "cpu": {"percent": 61.8, "count": 10, "freq": {"current": 3228, "min": 600, "max": 3228}}, "memory": {"total_gb": 32.0, "used_gb": 21.3, "available_gb": 2.84, "percent": 91.1}, "disk": {"total_gb": 926.35, "used_gb": 18.97, "free_gb": 626.88, "percent": 2.05}, "gpu": {"available": true, "type": "Apple M1 Pro", "utilization_percent": 64.07, "memory_used_mb": null, "memory_total_mb": null}, "training_processes": [{"pid": 9769, "name": "full-line-inference", "cmdline": "/Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/full-line-inference.zip_extracted/full-line-inference.app/Contents/MacOS/full-line-inference --model /Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/flcc.model --type llama --beam-size 2 --iterations-count 20 --context-ratio 0.5 --min-cached 5 --max-missing 30 --max-model-ctx 0", "cpu_percent": 0, "memory_mb": 4.23}, {"pid": 55559, "name": "python3.13", "cmdline": "python huanhuan_train.py", "cpu_percent": 30.1, "memory_mb": 97.95}]}
{"timestamp": "2025-07-18T17:09:31.192769", "cpu": {"percent": 59.1, "count": 10, "freq": {"current": 3228, "min": 600, "max": 3228}}, "memory": {"total_gb": 32.0, "used_gb": 15.9, "available_gb": 4.14, "percent": 87.0}, "disk": {"total_gb": 926.35, "used_gb": 18.97, "free_gb": 627.88, "percent": 2.05}, "gpu": {"available": true, "type": "Apple M1 Pro", "utilization_percent": 76.93, "memory_used_mb": null, "memory_total_mb": null}, "training_processes": [{"pid": 9769, "name": "full-line-inference", "cmdline": "/Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/full-line-inference.zip_extracted/full-line-inference.app/Contents/MacOS/full-line-inference --model /Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/flcc.model --type llama --beam-size 2 --iterations-count 20 --context-ratio 0.5 --min-cached 5 --max-missing 30 --max-model-ctx 0", "cpu_percent": 0, "memory_mb": 4.11}, {"pid": 55559, "name": "python3.13", "cmdline": "python huanhuan_train.py", "cpu_percent": 28.6, "memory_mb": 57.47}]}
{"timestamp": "2025-07-18T17:09:39.476547", "cpu": {"percent": 69.3, "count": 10, "freq": {"current": 3228, "min": 600, "max": 3228}}, "memory": {"total_gb": 32.0, "used_gb": 16.12, "available_gb": 7.8, "percent": 75.6}, "disk": {"total_gb": 926.35, "used_gb": 18.97, "free_gb": 626.88, "percent": 2.05}, "gpu": {"available": true, "type": "Apple M1 Pro", "utilization_percent": 47.48, "memory_used_mb": null, "memory_total_mb": null}, "training_processes": [{"pid": 9769, "name": "full-line-inference", "cmdline": "/Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/full-line-inference.zip_extracted/full-line-inference.app/Contents/MacOS/full-line-inference --model /Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/flcc.model --type llama --beam-size 2 --iterations-count 20 --context-ratio 0.5 --min-cached 5 --max-missing 30 --max-model-ctx 0", "cpu_percent": 0, "memory_mb": 4.08}, {"pid": 55559, "name": "python3.13", "cmdline": "python huanhuan_train.py", "cpu_percent": 32.6, "memory_mb": 52.44}]}
{"timestamp": "2025-07-18T17:09:47.760037", "cpu": {"percent": 39.3, "count": 10, "freq": {"current": 3228, "min": 600, "max": 3228}}, "memory": {"total_gb": 32.0, "used_gb": 21.7, "available_gb": 2.4, "percent": 92.5}, "disk": {"total_gb": 926.35, "used_gb": 18.97, "free_gb": 627.88, "percent": 2.05}, "gpu": {"available": true, "type": "Apple M1 Pro", "utilization_percent": 100.0, "memory_used_mb": null, "memory_total_mb": null}, "training_processes": [{"pid": 9769, "name": "full-line-inference", "cmdline": "/Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/full-line-inference.zip_extracted/full-line-inference.app/Contents/MacOS/full-line-inference --model /Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/flcc.model --type llama --beam-size 2 --iterations-count 20 --context-ratio 0.5 --min-cached 5 --max-missing 30 --max-model-ctx 0", "cpu_percent": 0, "memory_mb": 4.08}, {"pid": 55559, "name": "python3.13", "cmdline": "python huanhuan_train.py", "cpu_percent": 33.7, "memory_mb": 118.75}]}
{"timestamp": "2025-07-18T17:09:56.095595", "cpu": {"percent": 58.7, "count": 10, "freq": {"current": 3228, "min": 600, "max": 3228}}, "memory": {"total_gb": 32.0, "used_gb": 19.92, "available_gb": 2.88, "percent": 91.0}, "disk": {"total_gb": 926.35, "used_gb": 18.97, "free_gb": 626.88, "percent": 2.05}, "gpu": {"available": true, "type": "Apple M1 Pro", "utilization_percent": 40.72, "memory_used_mb": null, "memory_total_mb": null}, "training_processes": [{"pid": 9769, "name": "full-line-inference", "cmdline": "/Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/full-line-inference.zip_extracted/full-line-inference.app/Contents/MacOS/full-line-inference --model /Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/flcc.model --type llama --beam-size 2 --iterations-count 20 --context-ratio 0.5 --min-cached 5 --max-missing 30 --max-model-ctx 0", "cpu_percent": 0, "memory_mb": 4.08}, {"pid": 55559, "name": "python3.13", "cmdline": "python huanhuan_train.py", "cpu_percent": 32.1, "memory_mb": 77.22}]}
{"timestamp": "2025-07-18T17:10:05.029960", "cpu": {"percent": 42.0, "count": 10, "freq": {"current": 3228, "min": 600, "max": 3228}}, "memory": {"total_gb": 32.0, "used_gb": 15.15, "available_gb": 8.68, "percent": 72.9}, "disk": {"total_gb": 926.35, "used_gb": 18.97, "free_gb": 626.87, "percent": 2.05}, "gpu": {"available": true, "type": "Apple M1 Pro", "utilization_percent": 14.49, "memory_used_mb": null, "memory_total_mb": null}, "training_processes": [{"pid": 9769, "name": "full-line-inference", "cmdline": "/Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/full-line-inference.zip_extracted/full-line-inference.app/Contents/MacOS/full-line-inference --model /Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/flcc.model --type llama --beam-size 2 --iterations-count 20 --context-ratio 0.5 --min-cached 5 --max-missing 30 --max-model-ctx 0", "cpu_percent": 0, "memory_mb": 4.22}, {"pid": 55559, "name": "python3.13", "cmdline": "python huanhuan_train.py", "cpu_percent": 26.2, "memory_mb": 59.31}]}
{"timestamp": "2025-07-18T17:10:13.326747", "cpu": {"percent": 86.5, "count": 10, "freq": {"current": 3228, "min": 600, "max": 3228}}, "memory": {"total_gb": 32.0, "used_gb": 18.46, "available_gb": 3.24, "percent": 89.9}, "disk": {"total_gb": 926.35, "used_gb": 18.97, "free_gb": 627.88, "percent": 2.05}, "gpu": {"available": true, "type": "Apple M1 Pro", "utilization_percent": 23.22, "memory_used_mb": null, "memory_total_mb": null}, "training_processes": [{"pid": 9769, "name": "full-line-inference", "cmdline": "/Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/full-line-inference.zip_extracted/full-line-inference.app/Contents/MacOS/full-line-inference --model /Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/flcc.model --type llama --beam-size 2 --iterations-count 20 --context-ratio 0.5 --min-cached 5 --max-missing 30 --max-model-ctx 0", "cpu_percent": 0, "memory_mb": 4.03}, {"pid": 55559, "name": "python3.13", "cmdline": "python huanhuan_train.py", "cpu_percent": 33.1, "memory_mb": 51.92}]}
{"timestamp": "2025-07-18T17:10:22.597383", "cpu": {"percent": 45.3, "count": 10, "freq": {"current": 3228, "min": 600, "max": 3228}}, "memory": {"total_gb": 32.0, "used_gb": 18.73, "available_gb": 3.79, "percent": 88.2}, "disk": {"total_gb": 926.35, "used_gb": 18.97, "free_gb": 627.88, "percent": 2.05}, "gpu": {"available": true, "type": "Apple M1 Pro", "utilization_percent": 28.42, "memory_used_mb": null, "memory_total_mb": null}, "training_processes": [{"pid": 9769, "name": "full-line-inference", "cmdline": "/Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/full-line-inference.zip_extracted/full-line-inference.app/Contents/MacOS/full-line-inference --model /Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/flcc.model --type llama --beam-size 2 --iterations-count 20 --context-ratio 0.5 --min-cached 5 --max-missing 30 --max-model-ctx 0", "cpu_percent": 0, "memory_mb": 4.27}, {"pid": 55559, "name": "python3.13", "cmdline": "python huanhuan_train.py", "cpu_percent": 27.7, "memory_mb": 43.27}]}
{"timestamp": "2025-07-18T17:10:31.243902", "cpu": {"percent": 52.9, "count": 10, "freq": {"current": 3228, "min": 600, "max": 3228}}, "memory": {"total_gb": 32.0, "used_gb": 18.28, "available_gb": 3.15, "percent": 90.2}, "disk": {"total_gb": 926.35, "used_gb": 18.97, "free_gb": 628.87, "percent": 2.05}, "gpu": {"available": true, "type": "Apple M1 Pro", "utilization_percent": 35.13, "memory_used_mb": null, "memory_total_mb": null}, "training_processes": [{"pid": 9769, "name": "full-line-inference", "cmdline": "/Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/full-line-inference.zip_extracted/full-line-inference.app/Contents/MacOS/full-line-inference --model /Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/flcc.model --type llama --beam-size 2 --iterations-count 20 --context-ratio 0.5 --min-cached 5 --max-missing 30 --max-model-ctx 0", "cpu_percent": 0, "memory_mb": 4.11}, {"pid": 55559, "name": "python3.13", "cmdline": "python huanhuan_train.py", "cpu_percent": 31.8, "memory_mb": 73.05}]}
{"timestamp": "2025-07-18T17:10:39.555452", "cpu": {"percent": 43.4, "count": 10, "freq": {"current": 3228, "min": 600, "max": 3228}}, "memory": {"total_gb": 32.0, "used_gb": 17.03, "available_gb": 7.82, "percent": 75.6}, "disk": {"total_gb": 926.35, "used_gb": 18.97, "free_gb": 626.88, "percent": 2.05}, "gpu": {"available": true, "type": "Apple M1 Pro", "utilization_percent": 6.22, "memory_used_mb": null, "memory_total_mb": null}, "training_processes": [{"pid": 9769, "name": "full-line-inference", "cmdline": "/Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/full-line-inference.zip_extracted/full-line-inference.app/Contents/MacOS/full-line-inference --model /Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/flcc.model --type llama --beam-size 2 --iterations-count 20 --context-ratio 0.5 --min-cached 5 --max-missing 30 --max-model-ctx 0", "cpu_percent": 0, "memory_mb": 4.06}, {"pid": 55559, "name": "python3.13", "cmdline": "python huanhuan_train.py", "cpu_percent": 24.7, "memory_mb": 67.64}]}
{"timestamp": "2025-07-18T17:10:47.565477", "cpu": {"percent": 48.7, "count": 10, "freq": {"current": 3228, "min": 600, "max": 3228}}, "memory": {"total_gb": 32.0, "used_gb": 20.39, "available_gb": 3.09, "percent": 90.3}, "disk": {"total_gb": 926.35, "used_gb": 18.97, "free_gb": 626.88, "percent": 2.05}, "gpu": {"available": true, "type": "Apple M1 Pro", "utilization_percent": 61.2, "memory_used_mb": null, "memory_total_mb": null}, "training_processes": [{"pid": 9769, "name": "full-line-inference", "cmdline": "/Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/full-line-inference.zip_extracted/full-line-inference.app/Contents/MacOS/full-line-inference --model /Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/flcc.model --type llama --beam-size 2 --iterations-count 20 --context-ratio 0.5 --min-cached 5 --max-missing 30 --max-model-ctx 0", "cpu_percent": 0, "memory_mb": 4.06}, {"pid": 55559, "name": "python3.13", "cmdline": "python huanhuan_train.py", "cpu_percent": 30.7, "memory_mb": 123.45}]}
{"timestamp": "2025-07-18T17:10:55.821332", "cpu": {"percent": 57.0, "count": 10, "freq": {"current": 3228, "min": 600, "max": 3228}}, "memory": {"total_gb": 32.0, "used_gb": 21.93, "available_gb": 2.99, "percent": 90.7}, "disk": {"total_gb": 926.35, "used_gb": 18.97, "free_gb": 626.87, "percent": 2.05}, "gpu": {"available": true, "type": "Apple M1 Pro", "utilization_percent": 81.3, "memory_used_mb": null, "memory_total_mb": null}, "training_processes": [{"pid": 9769, "name": "full-line-inference", "cmdline": "/Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/full-line-inference.zip_extracted/full-line-inference.app/Contents/MacOS/full-line-inference --model /Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/flcc.model --type llama --beam-size 2 --iterations-count 20 --context-ratio 0.5 --min-cached 5 --max-missing 30 --max-model-ctx 0", "cpu_percent": 0, "memory_mb": 4.17}, {"pid": 55559, "name": "python3.13", "cmdline": "python huanhuan_train.py", "cpu_percent": 34.3, "memory_mb": 158.8}]}
{"timestamp": "2025-07-18T17:11:03.913505", "cpu": {"percent": 47.4, "count": 10, "freq": {"current": 3228, "min": 600, "max": 3228}}, "memory": {"total_gb": 32.0, "used_gb": 18.77, "available_gb": 3.17, "percent": 90.1}, "disk": {"total_gb": 926.35, "used_gb": 18.97, "free_gb": 626.87, "percent": 2.05}, "gpu": {"available": true, "type": "Apple M1 Pro", "utilization_percent": 62.54, "memory_used_mb": null, "memory_total_mb": null}, "training_processes": [{"pid": 9769, "name": "full-line-inference", "cmdline": "/Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/full-line-inference.zip_extracted/full-line-inference.app/Contents/MacOS/full-line-inference --model /Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/flcc.model --type llama --beam-size 2 --iterations-count 20 --context-ratio 0.5 --min-cached 5 --max-missing 30 --max-model-ctx 0", "cpu_percent": 0, "memory_mb": 4.03}, {"pid": 55559, "name": "python3.13", "cmdline": "python huanhuan_train.py", "cpu_percent": 28.5, "memory_mb": 35.09}]}
{"timestamp": "2025-07-18T17:11:12.423549", "cpu": {"percent": 50.7, "count": 10, "freq": {"current": 3228, "min": 600, "max": 3228}}, "memory": {"total_gb": 32.0, "used_gb": 21.69, "available_gb": 2.41, "percent": 92.5}, "disk": {"total_gb": 926.35, "used_gb": 18.97, "free_gb": 626.88, "percent": 2.05}, "gpu": {"available": true, "type": "Apple M1 Pro", "utilization_percent": 13.01, "memory_used_mb": null, "memory_total_mb": null}, "training_processes": [{"pid": 9769, "name": "full-line-inference", "cmdline": "/Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/full-line-inference.zip_extracted/full-line-inference.app/Contents/MacOS/full-line-inference --model /Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/flcc.model --type llama --beam-size 2 --iterations-count 20 --context-ratio 0.5 --min-cached 5 --max-missing 30 --max-model-ctx 0", "cpu_percent": 0, "memory_mb": 4.17}, {"pid": 55559, "name": "python3.13", "cmdline": "python huanhuan_train.py", "cpu_percent": 28.6, "memory_mb": 99.58}]}
{"timestamp": "2025-07-18T17:11:22.559013", "cpu": {"percent": 65.5, "count": 10, "freq": {"current": 3228, "min": 600, "max": 3228}}, "memory": {"total_gb": 32.0, "used_gb": 16.54, "available_gb": 3.87, "percent": 87.9}, "disk": {"total_gb": 926.35, "used_gb": 18.97, "free_gb": 629.88, "percent": 2.05}, "gpu": {"available": true, "type": "Apple M1 Pro", "utilization_percent": 39.81, "memory_used_mb": null, "memory_total_mb": null}, "training_processes": [{"pid": 9769, "name": "full-line-inference", "cmdline": "/Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/full-line-inference.zip_extracted/full-line-inference.app/Contents/MacOS/full-line-inference --model /Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/flcc.model --type llama --beam-size 2 --iterations-count 20 --context-ratio 0.5 --min-cached 5 --max-missing 30 --max-model-ctx 0", "cpu_percent": 0, "memory_mb": 4.22}, {"pid": 55559, "name": "python3.13", "cmdline": "python huanhuan_train.py", "cpu_percent": 25.2, "memory_mb": 59.2}]}
{"timestamp": "2025-07-18T17:11:31.720137", "cpu": {"percent": 72.3, "count": 10, "freq": {"current": 3228, "min": 600, "max": 3228}}, "memory": {"total_gb": 32.0, "used_gb": 17.05, "available_gb": 3.97, "percent": 87.6}, "disk": {"total_gb": 926.35, "used_gb": 18.97, "free_gb": 628.87, "percent": 2.05}, "gpu": {"available": true, "type": "Apple M1 Pro", "utilization_percent": 74.94, "memory_used_mb": null, "memory_total_mb": null}, "training_processes": [{"pid": 9769, "name": "full-line-inference", "cmdline": "/Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/full-line-inference.zip_extracted/full-line-inference.app/Contents/MacOS/full-line-inference --model /Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/flcc.model --type llama --beam-size 2 --iterations-count 20 --context-ratio 0.5 --min-cached 5 --max-missing 30 --max-model-ctx 0", "cpu_percent": 0, "memory_mb": 4.25}, {"pid": 55559, "name": "python3.13", "cmdline": "python huanhuan_train.py", "cpu_percent": 23.2, "memory_mb": 51.11}]}
{"timestamp": "2025-07-18T17:11:40.795760", "cpu": {"percent": 70.7, "count": 10, "freq": {"current": 3228, "min": 600, "max": 3228}}, "memory": {"total_gb": 32.0, "used_gb": 14.51, "available_gb": 4.75, "percent": 85.2}, "disk": {"total_gb": 926.35, "used_gb": 18.97, "free_gb": 630.88, "percent": 2.05}, "gpu": {"available": true, "type": "Apple M1 Pro", "utilization_percent": 17.41, "memory_used_mb": null, "memory_total_mb": null}, "training_processes": [{"pid": 9769, "name": "full-line-inference", "cmdline": "/Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/full-line-inference.zip_extracted/full-line-inference.app/Contents/MacOS/full-line-inference --model /Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/flcc.model --type llama --beam-size 2 --iterations-count 20 --context-ratio 0.5 --min-cached 5 --max-missing 30 --max-model-ctx 0", "cpu_percent": 0, "memory_mb": 4.09}, {"pid": 55559, "name": "python3.13", "cmdline": "python huanhuan_train.py", "cpu_percent": 26.4, "memory_mb": 65.67}]}
{"timestamp": "2025-07-18T17:11:49.129532", "cpu": {"percent": 70.4, "count": 10, "freq": {"current": 3228, "min": 600, "max": 3228}}, "memory": {"total_gb": 32.0, "used_gb": 19.85, "available_gb": 2.79, "percent": 91.3}, "disk": {"total_gb": 926.35, "used_gb": 18.97, "free_gb": 627.87, "percent": 2.05}, "gpu": {"available": true, "type": "Apple M1 Pro", "utilization_percent": 43.74, "memory_used_mb": null, "memory_total_mb": null}, "training_processes": [{"pid": 9769, "name": "full-line-inference", "cmdline": "/Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/full-line-inference.zip_extracted/full-line-inference.app/Contents/MacOS/full-line-inference --model /Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/flcc.model --type llama --beam-size 2 --iterations-count 20 --context-ratio 0.5 --min-cached 5 --max-missing 30 --max-model-ctx 0", "cpu_percent": 0, "memory_mb": 3.92}, {"pid": 55559, "name": "python3.13", "cmdline": "python huanhuan_train.py", "cpu_percent": 26.6, "memory_mb": 104.11}]}
{"timestamp": "2025-07-18T17:11:58.182282", "cpu": {"percent": 26.2, "count": 10, "freq": {"current": 3228, "min": 600, "max": 3228}}, "memory": {"total_gb": 32.0, "used_gb": 13.06, "available_gb": 6.44, "percent": 79.9}, "disk": {"total_gb": 926.35, "used_gb": 18.97, "free_gb": 627.87, "percent": 2.05}, "gpu": {"available": true, "type": "Apple M1 Pro", "utilization_percent": 7.85, "memory_used_mb": null, "memory_total_mb": null}, "training_processes": [{"pid": 9769, "name": "full-line-inference", "cmdline": "/Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/full-line-inference.zip_extracted/full-line-inference.app/Contents/MacOS/full-line-inference --model /Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/flcc.model --type llama --beam-size 2 --iterations-count 20 --context-ratio 0.5 --min-cached 5 --max-missing 30 --max-model-ctx 0", "cpu_percent": 0, "memory_mb": 4.25}, {"pid": 55559, "name": "python3.13", "cmdline": "python huanhuan_train.py", "cpu_percent": 14.1, "memory_mb": 46.81}]}
{"timestamp": "2025-07-18T17:12:06.000581", "cpu": {"percent": 64.1, "count": 10, "freq": {"current": 3228, "min": 600, "max": 3228}}, "memory": {"total_gb": 32.0, "used_gb": 20.28, "available_gb": 2.79, "percent": 91.3}, "disk": {"total_gb": 926.35, "used_gb": 18.97, "free_gb": 627.87, "percent": 2.05}, "gpu": {"available": true, "type": "Apple M1 Pro", "utilization_percent": 73.43, "memory_used_mb": null, "memory_total_mb": null}, "training_processes": [{"pid": 9769, "name": "full-line-inference", "cmdline": "/Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/full-line-inference.zip_extracted/full-line-inference.app/Contents/MacOS/full-line-inference --model /Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/flcc.model --type llama --beam-size 2 --iterations-count 20 --context-ratio 0.5 --min-cached 5 --max-missing 30 --max-model-ctx 0", "cpu_percent": 0, "memory_mb": 4.06}, {"pid": 55559, "name": "python3.13", "cmdline": "python huanhuan_train.py", "cpu_percent": 32.3, "memory_mb": 131.28}]}
{"timestamp": "2025-07-18T17:12:14.208841", "cpu": {"percent": 41.9, "count": 10, "freq": {"current": 3228, "min": 600, "max": 3228}}, "memory": {"total_gb": 32.0, "used_gb": 17.46, "available_gb": 3.62, "percent": 88.7}, "disk": {"total_gb": 926.35, "used_gb": 18.97, "free_gb": 626.88, "percent": 2.05}, "gpu": {"available": true, "type": "Apple M1 Pro", "utilization_percent": 24.73, "memory_used_mb": null, "memory_total_mb": null}, "training_processes": [{"pid": 9769, "name": "full-line-inference", "cmdline": "/Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/full-line-inference.zip_extracted/full-line-inference.app/Contents/MacOS/full-line-inference --model /Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/flcc.model --type llama --beam-size 2 --iterations-count 20 --context-ratio 0.5 --min-cached 5 --max-missing 30 --max-model-ctx 0", "cpu_percent": 0, "memory_mb": 4.09}, {"pid": 55559, "name": "python3.13", "cmdline": "python huanhuan_train.py", "cpu_percent": 30.6, "memory_mb": 33.94}]}
{"timestamp": "2025-07-18T17:12:23.056072", "cpu": {"percent": 44.1, "count": 10, "freq": {"current": 3228, "min": 600, "max": 3228}}, "memory": {"total_gb": 32.0, "used_gb": 21.66, "available_gb": 2.53, "percent": 92.1}, "disk": {"total_gb": 926.35, "used_gb": 18.97, "free_gb": 626.87, "percent": 2.05}, "gpu": {"available": true, "type": "Apple M1 Pro", "utilization_percent": 6.28, "memory_used_mb": null, "memory_total_mb": null}, "training_processes": [{"pid": 9769, "name": "full-line-inference", "cmdline": "/Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/full-line-inference.zip_extracted/full-line-inference.app/Contents/MacOS/full-line-inference --model /Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/flcc.model --type llama --beam-size 2 --iterations-count 20 --context-ratio 0.5 --min-cached 5 --max-missing 30 --max-model-ctx 0", "cpu_percent": 0, "memory_mb": 4.25}, {"pid": 55559, "name": "python3.13", "cmdline": "python huanhuan_train.py", "cpu_percent": 33.4, "memory_mb": 80.22}]}
{"timestamp": "2025-07-18T17:12:30.987631", "cpu": {"percent": 35.8, "count": 10, "freq": {"current": 3228, "min": 600, "max": 3228}}, "memory": {"total_gb": 32.0, "used_gb": 14.41, "available_gb": 7.56, "percent": 76.4}, "disk": {"total_gb": 926.35, "used_gb": 18.97, "free_gb": 626.87, "percent": 2.05}, "gpu": {"available": true, "type": "Apple M1 Pro", "utilization_percent": 13.53, "memory_used_mb": null, "memory_total_mb": null}, "training_processes": [{"pid": 9769, "name": "full-line-inference", "cmdline": "/Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/full-line-inference.zip_extracted/full-line-inference.app/Contents/MacOS/full-line-inference --model /Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/flcc.model --type llama --beam-size 2 --iterations-count 20 --context-ratio 0.5 --min-cached 5 --max-missing 30 --max-model-ctx 0", "cpu_percent": 0, "memory_mb": 4.09}, {"pid": 55559, "name": "python3.13", "cmdline": "python huanhuan_train.py", "cpu_percent": 21.5, "memory_mb": 48.28}]}
{"timestamp": "2025-07-18T17:12:38.948586", "cpu": {"percent": 49.6, "count": 10, "freq": {"current": 3228, "min": 600, "max": 3228}}, "memory": {"total_gb": 32.0, "used_gb": 21.62, "available_gb": 2.42, "percent": 92.4}, "disk": {"total_gb": 926.35, "used_gb": 18.97, "free_gb": 627.86, "percent": 2.05}, "gpu": {"available": true, "type": "Apple M1 Pro", "utilization_percent": 99.82, "memory_used_mb": null, "memory_total_mb": null}, "training_processes": [{"pid": 9769, "name": "full-line-inference", "cmdline": "/Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/full-line-inference.zip_extracted/full-line-inference.app/Contents/MacOS/full-line-inference --model /Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/flcc.model --type llama --beam-size 2 --iterations-count 20 --context-ratio 0.5 --min-cached 5 --max-missing 30 --max-model-ctx 0", "cpu_percent": 0, "memory_mb": 4.06}, {"pid": 55559, "name": "python3.13", "cmdline": "python huanhuan_train.py", "cpu_percent": 37.9, "memory_mb": 90.97}]}
{"timestamp": "2025-07-18T17:12:47.231019", "cpu": {"percent": 64.4, "count": 10, "freq": {"current": 3228, "min": 600, "max": 3228}}, "memory": {"total_gb": 32.0, "used_gb": 21.44, "available_gb": 2.66, "percent": 91.7}, "disk": {"total_gb": 926.35, "used_gb": 18.97, "free_gb": 626.87, "percent": 2.05}, "gpu": {"available": true, "type": "Apple M1 Pro", "utilization_percent": 54.07, "memory_used_mb": null, "memory_total_mb": null}, "training_processes": [{"pid": 9769, "name": "full-line-inference", "cmdline": "/Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/full-line-inference.zip_extracted/full-line-inference.app/Contents/MacOS/full-line-inference --model /Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/flcc.model --type llama --beam-size 2 --iterations-count 20 --context-ratio 0.5 --min-cached 5 --max-missing 30 --max-model-ctx 0", "cpu_percent": 0, "memory_mb": 4.06}, {"pid": 55559, "name": "python3.13", "cmdline": "python huanhuan_train.py", "cpu_percent": 29.2, "memory_mb": 23.36}]}
{"timestamp": "2025-07-18T17:12:57.451117", "cpu": {"percent": 35.6, "count": 10, "freq": {"current": 3228, "min": 600, "max": 3228}}, "memory": {"total_gb": 32.0, "used_gb": 14.59, "available_gb": 5.28, "percent": 83.5}, "disk": {"total_gb": 926.35, "used_gb": 18.97, "free_gb": 628.87, "percent": 2.05}, "gpu": {"available": true, "type": "Apple M1 Pro", "utilization_percent": 23.19, "memory_used_mb": null, "memory_total_mb": null}, "training_processes": [{"pid": 9769, "name": "full-line-inference", "cmdline": "/Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/full-line-inference.zip_extracted/full-line-inference.app/Contents/MacOS/full-line-inference --model /Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/flcc.model --type llama --beam-size 2 --iterations-count 20 --context-ratio 0.5 --min-cached 5 --max-missing 30 --max-model-ctx 0", "cpu_percent": 0, "memory_mb": 4.06}, {"pid": 55559, "name": "python3.13", "cmdline": "python huanhuan_train.py", "cpu_percent": 21.9, "memory_mb": 29.7}]}
{"timestamp": "2025-07-18T17:13:06.103669", "cpu": {"percent": 60.5, "count": 10, "freq": {"current": 3228, "min": 600, "max": 3228}}, "memory": {"total_gb": 32.0, "used_gb": 14.0, "available_gb": 4.34, "percent": 86.4}, "disk": {"total_gb": 926.35, "used_gb": 18.97, "free_gb": 628.87, "percent": 2.05}, "gpu": {"available": true, "type": "Apple M1 Pro", "utilization_percent": 22.7, "memory_used_mb": null, "memory_total_mb": null}, "training_processes": [{"pid": 9769, "name": "full-line-inference", "cmdline": "/Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/full-line-inference.zip_extracted/full-line-inference.app/Contents/MacOS/full-line-inference --model /Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/flcc.model --type llama --beam-size 2 --iterations-count 20 --context-ratio 0.5 --min-cached 5 --max-missing 30 --max-model-ctx 0", "cpu_percent": 0, "memory_mb": 4.06}, {"pid": 55559, "name": "python3.13", "cmdline": "python huanhuan_train.py", "cpu_percent": 29.7, "memory_mb": 40.98}]}
{"timestamp": "2025-07-18T17:13:14.617689", "cpu": {"percent": 65.7, "count": 10, "freq": {"current": 3228, "min": 600, "max": 3228}}, "memory": {"total_gb": 32.0, "used_gb": 16.53, "available_gb": 3.74, "percent": 88.3}, "disk": {"total_gb": 926.35, "used_gb": 18.97, "free_gb": 628.86, "percent": 2.05}, "gpu": {"available": true, "type": "Apple M1 Pro", "utilization_percent": 12.15, "memory_used_mb": null, "memory_total_mb": null}, "training_processes": [{"pid": 9769, "name": "full-line-inference", "cmdline": "/Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/full-line-inference.zip_extracted/full-line-inference.app/Contents/MacOS/full-line-inference --model /Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/flcc.model --type llama --beam-size 2 --iterations-count 20 --context-ratio 0.5 --min-cached 5 --max-missing 30 --max-model-ctx 0", "cpu_percent": 0, "memory_mb": 4.09}, {"pid": 55559, "name": "python3.13", "cmdline": "python huanhuan_train.py", "cpu_percent": 27.3, "memory_mb": 60.09}]}
{"timestamp": "2025-07-18T17:13:23.364077", "cpu": {"percent": 86.6, "count": 10, "freq": {"current": 3228, "min": 600, "max": 3228}}, "memory": {"total_gb": 32.0, "used_gb": 14.87, "available_gb": 4.71, "percent": 85.3}, "disk": {"total_gb": 926.35, "used_gb": 18.97, "free_gb": 629.87, "percent": 2.05}, "gpu": {"available": true, "type": "Apple M1 Pro", "utilization_percent": 68.54, "memory_used_mb": null, "memory_total_mb": null}, "training_processes": [{"pid": 9769, "name": "full-line-inference", "cmdline": "/Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/full-line-inference.zip_extracted/full-line-inference.app/Contents/MacOS/full-line-inference --model /Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/flcc.model --type llama --beam-size 2 --iterations-count 20 --context-ratio 0.5 --min-cached 5 --max-missing 30 --max-model-ctx 0", "cpu_percent": 0, "memory_mb": 4.22}, {"pid": 55559, "name": "python3.13", "cmdline": "python huanhuan_train.py", "cpu_percent": 26.6, "memory_mb": 50.67}]}
{"timestamp": "2025-07-18T17:13:32.111219", "cpu": {"percent": 61.7, "count": 10, "freq": {"current": 3228, "min": 600, "max": 3228}}, "memory": {"total_gb": 32.0, "used_gb": 15.03, "available_gb": 4.19, "percent": 86.9}, "disk": {"total_gb": 926.35, "used_gb": 18.97, "free_gb": 629.87, "percent": 2.05}, "gpu": {"available": true, "type": "Apple M1 Pro", "utilization_percent": 24.4, "memory_used_mb": null, "memory_total_mb": null}, "training_processes": [{"pid": 9769, "name": "full-line-inference", "cmdline": "/Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/full-line-inference.zip_extracted/full-line-inference.app/Contents/MacOS/full-line-inference --model /Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/flcc.model --type llama --beam-size 2 --iterations-count 20 --context-ratio 0.5 --min-cached 5 --max-missing 30 --max-model-ctx 0", "cpu_percent": 0, "memory_mb": 4.22}, {"pid": 55559, "name": "python3.13", "cmdline": "python huanhuan_train.py", "cpu_percent": 23.0, "memory_mb": 29.36}]}
{"timestamp": "2025-07-18T17:13:42.267655", "cpu": {"percent": 52.6, "count": 10, "freq": {"current": 3228, "min": 600, "max": 3228}}, "memory": {"total_gb": 32.0, "used_gb": 14.16, "available_gb": 4.9, "percent": 84.7}, "disk": {"total_gb": 926.35, "used_gb": 18.97, "free_gb": 629.86, "percent": 2.05}, "gpu": {"available": true, "type": "Apple M1 Pro", "utilization_percent": 19.49, "memory_used_mb": null, "memory_total_mb": null}, "training_processes": [{"pid": 9769, "name": "full-line-inference", "cmdline": "/Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/full-line-inference.zip_extracted/full-line-inference.app/Contents/MacOS/full-line-inference --model /Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/flcc.model --type llama --beam-size 2 --iterations-count 20 --context-ratio 0.5 --min-cached 5 --max-missing 30 --max-model-ctx 0", "cpu_percent": 0, "memory_mb": 4.27}, {"pid": 55559, "name": "python3.13", "cmdline": "python huanhuan_train.py", "cpu_percent": 21.0, "memory_mb": 43.27}]}
{"timestamp": "2025-07-18T17:13:50.405375", "cpu": {"percent": 71.0, "count": 10, "freq": {"current": 3228, "min": 600, "max": 3228}}, "memory": {"total_gb": 32.0, "used_gb": 17.65, "available_gb": 4.07, "percent": 87.3}, "disk": {"total_gb": 926.35, "used_gb": 18.97, "free_gb": 628.87, "percent": 2.05}, "gpu": {"available": true, "type": "Apple M1 Pro", "utilization_percent": 28.67, "memory_used_mb": null, "memory_total_mb": null}, "training_processes": [{"pid": 9769, "name": "full-line-inference", "cmdline": "/Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/full-line-inference.zip_extracted/full-line-inference.app/Contents/MacOS/full-line-inference --model /Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/flcc.model --type llama --beam-size 2 --iterations-count 20 --context-ratio 0.5 --min-cached 5 --max-missing 30 --max-model-ctx 0", "cpu_percent": 0, "memory_mb": 4.09}, {"pid": 55559, "name": "python3.13", "cmdline": "python huanhuan_train.py", "cpu_percent": 28.5, "memory_mb": 48.28}]}
{"timestamp": "2025-07-18T17:13:58.900218", "cpu": {"percent": 47.4, "count": 10, "freq": {"current": 3228, "min": 600, "max": 3228}}, "memory": {"total_gb": 32.0, "used_gb": 20.53, "available_gb": 3.33, "percent": 89.6}, "disk": {"total_gb": 926.35, "used_gb": 18.97, "free_gb": 626.86, "percent": 2.05}, "gpu": {"available": true, "type": "Apple M1 Pro", "utilization_percent": 12.02, "memory_used_mb": null, "memory_total_mb": null}, "training_processes": [{"pid": 9769, "name": "full-line-inference", "cmdline": "/Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/full-line-inference.zip_extracted/full-line-inference.app/Contents/MacOS/full-line-inference --model /Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/flcc.model --type llama --beam-size 2 --iterations-count 20 --context-ratio 0.5 --min-cached 5 --max-missing 30 --max-model-ctx 0", "cpu_percent": 0, "memory_mb": 4.06}, {"pid": 55559, "name": "python3.13", "cmdline": "python huanhuan_train.py", "cpu_percent": 28.4, "memory_mb": 135.23}]}
{"timestamp": "2025-07-18T17:14:06.874733", "cpu": {"percent": 33.8, "count": 10, "freq": {"current": 3228, "min": 600, "max": 3228}}, "memory": {"total_gb": 32.0, "used_gb": 14.97, "available_gb": 8.51, "percent": 73.4}, "disk": {"total_gb": 926.35, "used_gb": 18.97, "free_gb": 625.86, "percent": 2.05}, "gpu": {"available": true, "type": "Apple M1 Pro", "utilization_percent": 9.2, "memory_used_mb": null, "memory_total_mb": null}, "training_processes": [{"pid": 9769, "name": "full-line-inference", "cmdline": "/Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/full-line-inference.zip_extracted/full-line-inference.app/Contents/MacOS/full-line-inference --model /Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/flcc.model --type llama --beam-size 2 --iterations-count 20 --context-ratio 0.5 --min-cached 5 --max-missing 30 --max-model-ctx 0", "cpu_percent": 0, "memory_mb": 4.23}, {"pid": 55559, "name": "python3.13", "cmdline": "python huanhuan_train.py", "cpu_percent": 21.2, "memory_mb": 49.8}]}
{"timestamp": "2025-07-18T17:14:14.900957", "cpu": {"percent": 53.3, "count": 10, "freq": {"current": 3228, "min": 600, "max": 3228}}, "memory": {"total_gb": 32.0, "used_gb": 19.96, "available_gb": 2.9, "percent": 90.9}, "disk": {"total_gb": 926.35, "used_gb": 18.97, "free_gb": 627.79, "percent": 2.05}, "gpu": {"available": true, "type": "Apple M1 Pro", "utilization_percent": 80.24, "memory_used_mb": null, "memory_total_mb": null}, "training_processes": [{"pid": 9769, "name": "full-line-inference", "cmdline": "/Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/full-line-inference.zip_extracted/full-line-inference.app/Contents/MacOS/full-line-inference --model /Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/flcc.model --type llama --beam-size 2 --iterations-count 20 --context-ratio 0.5 --min-cached 5 --max-missing 30 --max-model-ctx 0", "cpu_percent": 0, "memory_mb": 4.09}, {"pid": 55559, "name": "python3.13", "cmdline": "python huanhuan_train.py", "cpu_percent": 28.2, "memory_mb": 97.95}]}
{"timestamp": "2025-07-18T17:14:23.019006", "cpu": {"percent": 40.8, "count": 10, "freq": {"current": 3228, "min": 600, "max": 3228}}, "memory": {"total_gb": 32.0, "used_gb": 15.56, "available_gb": 4.8, "percent": 85.0}, "disk": {"total_gb": 926.35, "used_gb": 18.97, "free_gb": 626.8, "percent": 2.05}, "gpu": {"available": true, "type": "Apple M1 Pro", "utilization_percent": 38.4, "memory_used_mb": null, "memory_total_mb": null}, "training_processes": [{"pid": 9769, "name": "full-line-inference", "cmdline": "/Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/full-line-inference.zip_extracted/full-line-inference.app/Contents/MacOS/full-line-inference --model /Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/flcc.model --type llama --beam-size 2 --iterations-count 20 --context-ratio 0.5 --min-cached 5 --max-missing 30 --max-model-ctx 0", "cpu_percent": 0, "memory_mb": 4.25}, {"pid": 55559, "name": "python3.13", "cmdline": "python huanhuan_train.py", "cpu_percent": 29.3, "memory_mb": 52.88}]}
{"timestamp": "2025-07-18T17:14:31.355685", "cpu": {"percent": 74.7, "count": 10, "freq": {"current": 3228, "min": 600, "max": 3228}}, "memory": {"total_gb": 32.0, "used_gb": 21.03, "available_gb": 3.22, "percent": 89.9}, "disk": {"total_gb": 926.35, "used_gb": 18.97, "free_gb": 626.78, "percent": 2.05}, "gpu": {"available": true, "type": "Apple M1 Pro", "utilization_percent": 37.96, "memory_used_mb": null, "memory_total_mb": null}, "training_processes": [{"pid": 9769, "name": "full-line-inference", "cmdline": "/Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/full-line-inference.zip_extracted/full-line-inference.app/Contents/MacOS/full-line-inference --model /Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/flcc.model --type llama --beam-size 2 --iterations-count 20 --context-ratio 0.5 --min-cached 5 --max-missing 30 --max-model-ctx 0", "cpu_percent": 0, "memory_mb": 4.09}, {"pid": 55559, "name": "python3.13", "cmdline": "python huanhuan_train.py", "cpu_percent": 34.1, "memory_mb": 95.91}]}
{"timestamp": "2025-07-18T17:14:40.014065", "cpu": {"percent": 54.1, "count": 10, "freq": {"current": 3228, "min": 600, "max": 3228}}, "memory": {"total_gb": 32.0, "used_gb": 18.09, "available_gb": 3.29, "percent": 89.7}, "disk": {"total_gb": 926.35, "used_gb": 18.97, "free_gb": 626.78, "percent": 2.05}, "gpu": {"available": true, "type": "Apple M1 Pro", "utilization_percent": 40.14, "memory_used_mb": null, "memory_total_mb": null}, "training_processes": [{"pid": 9769, "name": "full-line-inference", "cmdline": "/Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/full-line-inference.zip_extracted/full-line-inference.app/Contents/MacOS/full-line-inference --model /Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/flcc.model --type llama --beam-size 2 --iterations-count 20 --context-ratio 0.5 --min-cached 5 --max-missing 30 --max-model-ctx 0", "cpu_percent": 0, "memory_mb": 3.97}, {"pid": 55559, "name": "python3.13", "cmdline": "python huanhuan_train.py", "cpu_percent": 30.7, "memory_mb": 72.47}]}
{"timestamp": "2025-07-18T17:14:48.409869", "cpu": {"percent": 81.7, "count": 10, "freq": {"current": 3228, "min": 600, "max": 3228}}, "memory": {"total_gb": 32.0, "used_gb": 13.57, "available_gb": 5.68, "percent": 82.2}, "disk": {"total_gb": 926.35, "used_gb": 18.97, "free_gb": 626.79, "percent": 2.05}, "gpu": {"available": true, "type": "Apple M1 Pro", "utilization_percent": 69.67, "memory_used_mb": null, "memory_total_mb": null}, "training_processes": [{"pid": 9769, "name": "full-line-inference", "cmdline": "/Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/full-line-inference.zip_extracted/full-line-inference.app/Contents/MacOS/full-line-inference --model /Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/flcc.model --type llama --beam-size 2 --iterations-count 20 --context-ratio 0.5 --min-cached 5 --max-missing 30 --max-model-ctx 0", "cpu_percent": 0, "memory_mb": 3.97}, {"pid": 55559, "name": "python3.13", "cmdline": "python huanhuan_train.py", "cpu_percent": 20.2, "memory_mb": 54.67}]}
{"timestamp": "2025-07-18T17:14:56.626178", "cpu": {"percent": 66.8, "count": 10, "freq": {"current": 3228, "min": 600, "max": 3228}}, "memory": {"total_gb": 32.0, "used_gb": 17.57, "available_gb": 3.29, "percent": 89.7}, "disk": {"total_gb": 926.35, "used_gb": 18.97, "free_gb": 627.8, "percent": 2.05}, "gpu": {"available": true, "type": "Apple M1 Pro", "utilization_percent": 8.2, "memory_used_mb": null, "memory_total_mb": null}, "training_processes": [{"pid": 9769, "name": "full-line-inference", "cmdline": "/Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/full-line-inference.zip_extracted/full-line-inference.app/Contents/MacOS/full-line-inference --model /Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/flcc.model --type llama --beam-size 2 --iterations-count 20 --context-ratio 0.5 --min-cached 5 --max-missing 30 --max-model-ctx 0", "cpu_percent": 0, "memory_mb": 4.06}, {"pid": 55559, "name": "python3.13", "cmdline": "python huanhuan_train.py", "cpu_percent": 31.8, "memory_mb": 54.31}]}
{"timestamp": "2025-07-18T17:15:04.962406", "cpu": {"percent": 43.6, "count": 10, "freq": {"current": 3228, "min": 600, "max": 3228}}, "memory": {"total_gb": 32.0, "used_gb": 18.91, "available_gb": 3.09, "percent": 90.3}, "disk": {"total_gb": 926.35, "used_gb": 18.97, "free_gb": 628.8, "percent": 2.05}, "gpu": {"available": true, "type": "Apple M1 Pro", "utilization_percent": 61.1, "memory_used_mb": null, "memory_total_mb": null}, "training_processes": [{"pid": 9769, "name": "full-line-inference", "cmdline": "/Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/full-line-inference.zip_extracted/full-line-inference.app/Contents/MacOS/full-line-inference --model /Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/flcc.model --type llama --beam-size 2 --iterations-count 20 --context-ratio 0.5 --min-cached 5 --max-missing 30 --max-model-ctx 0", "cpu_percent": 0, "memory_mb": 4.06}, {"pid": 55559, "name": "python3.13", "cmdline": "python huanhuan_train.py", "cpu_percent": 27.4, "memory_mb": 82.72}]}
{"timestamp": "2025-07-18T17:15:13.258824", "cpu": {"percent": 55.3, "count": 10, "freq": {"current": 3228, "min": 600, "max": 3228}}, "memory": {"total_gb": 32.0, "used_gb": 18.33, "available_gb": 4.41, "percent": 86.2}, "disk": {"total_gb": 926.35, "used_gb": 18.97, "free_gb": 625.8, "percent": 2.05}, "gpu": {"available": true, "type": "Apple M1 Pro", "utilization_percent": 57.78, "memory_used_mb": null, "memory_total_mb": null}, "training_processes": [{"pid": 9769, "name": "full-line-inference", "cmdline": "/Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/full-line-inference.zip_extracted/full-line-inference.app/Contents/MacOS/full-line-inference --model /Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/flcc.model --type llama --beam-size 2 --iterations-count 20 --context-ratio 0.5 --min-cached 5 --max-missing 30 --max-model-ctx 0", "cpu_percent": 0, "memory_mb": 4.06}, {"pid": 55559, "name": "python3.13", "cmdline": "python huanhuan_train.py", "cpu_percent": 28.0, "memory_mb": 52.08}]}
{"timestamp": "2025-07-18T17:15:22.746604", "cpu": {"percent": 88.6, "count": 10, "freq": {"current": 3228, "min": 600, "max": 3228}}, "memory": {"total_gb": 32.0, "used_gb": 13.34, "available_gb": 5.66, "percent": 82.3}, "disk": {"total_gb": 926.35, "used_gb": 18.97, "free_gb": 627.8, "percent": 2.05}, "gpu": {"available": true, "type": "Apple M1 Pro", "utilization_percent": 15.17, "memory_used_mb": null, "memory_total_mb": null}, "training_processes": [{"pid": 9769, "name": "full-line-inference", "cmdline": "/Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/full-line-inference.zip_extracted/full-line-inference.app/Contents/MacOS/full-line-inference --model /Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/flcc.model --type llama --beam-size 2 --iterations-count 20 --context-ratio 0.5 --min-cached 5 --max-missing 30 --max-model-ctx 0", "cpu_percent": 0, "memory_mb": 4.25}, {"pid": 55559, "name": "python3.13", "cmdline": "python huanhuan_train.py", "cpu_percent": 28.0, "memory_mb": 49.36}]}
{"timestamp": "2025-07-18T17:15:31.355090", "cpu": {"percent": 71.7, "count": 10, "freq": {"current": 3228, "min": 600, "max": 3228}}, "memory": {"total_gb": 32.0, "used_gb": 15.25, "available_gb": 3.96, "percent": 87.6}, "disk": {"total_gb": 926.35, "used_gb": 18.97, "free_gb": 629.8, "percent": 2.05}, "gpu": {"available": true, "type": "Apple M1 Pro", "utilization_percent": 13.94, "memory_used_mb": null, "memory_total_mb": null}, "training_processes": [{"pid": 9769, "name": "full-line-inference", "cmdline": "/Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/full-line-inference.zip_extracted/full-line-inference.app/Contents/MacOS/full-line-inference --model /Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/flcc.model --type llama --beam-size 2 --iterations-count 20 --context-ratio 0.5 --min-cached 5 --max-missing 30 --max-model-ctx 0", "cpu_percent": 0, "memory_mb": 4.09}, {"pid": 55559, "name": "python3.13", "cmdline": "python huanhuan_train.py", "cpu_percent": 24.1, "memory_mb": 57.7}]}
{"timestamp": "2025-07-18T17:15:39.628830", "cpu": {"percent": 53.5, "count": 10, "freq": {"current": 3228, "min": 600, "max": 3228}}, "memory": {"total_gb": 32.0, "used_gb": 20.13, "available_gb": 2.81, "percent": 91.2}, "disk": {"total_gb": 926.35, "used_gb": 18.97, "free_gb": 626.79, "percent": 2.05}, "gpu": {"available": true, "type": "Apple M1 Pro", "utilization_percent": 23.81, "memory_used_mb": null, "memory_total_mb": null}, "training_processes": [{"pid": 9769, "name": "full-line-inference", "cmdline": "/Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/full-line-inference.zip_extracted/full-line-inference.app/Contents/MacOS/full-line-inference --model /Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/flcc.model --type llama --beam-size 2 --iterations-count 20 --context-ratio 0.5 --min-cached 5 --max-missing 30 --max-model-ctx 0", "cpu_percent": 0, "memory_mb": 4.06}, {"pid": 55559, "name": "python3.13", "cmdline": "python huanhuan_train.py", "cpu_percent": 28.8, "memory_mb": 116.25}]}
{"timestamp": "2025-07-18T17:15:48.054014", "cpu": {"percent": 24.8, "count": 10, "freq": {"current": 3228, "min": 600, "max": 3228}}, "memory": {"total_gb": 32.0, "used_gb": 14.09, "available_gb": 7.29, "percent": 77.2}, "disk": {"total_gb": 926.35, "used_gb": 18.97, "free_gb": 626.79, "percent": 2.05}, "gpu": {"available": true, "type": "Apple M1 Pro", "utilization_percent": 15.04, "memory_used_mb": null, "memory_total_mb": null}, "training_processes": [{"pid": 9769, "name": "full-line-inference", "cmdline": "/Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/full-line-inference.zip_extracted/full-line-inference.app/Contents/MacOS/full-line-inference --model /Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/flcc.model --type llama --beam-size 2 --iterations-count 20 --context-ratio 0.5 --min-cached 5 --max-missing 30 --max-model-ctx 0", "cpu_percent": 0, "memory_mb": 4.22}, {"pid": 55559, "name": "python3.13", "cmdline": "python huanhuan_train.py", "cpu_percent": 17.2, "memory_mb": 50.91}]}
{"timestamp": "2025-07-18T17:15:56.002461", "cpu": {"percent": 52.9, "count": 10, "freq": {"current": 3228, "min": 600, "max": 3228}}, "memory": {"total_gb": 32.0, "used_gb": 19.74, "available_gb": 2.89, "percent": 91.0}, "disk": {"total_gb": 926.35, "used_gb": 18.97, "free_gb": 627.8, "percent": 2.05}, "gpu": {"available": true, "type": "Apple M1 Pro", "utilization_percent": 19.58, "memory_used_mb": null, "memory_total_mb": null}, "training_processes": [{"pid": 9769, "name": "full-line-inference", "cmdline": "/Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/full-line-inference.zip_extracted/full-line-inference.app/Contents/MacOS/full-line-inference --model /Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/flcc.model --type llama --beam-size 2 --iterations-count 20 --context-ratio 0.5 --min-cached 5 --max-missing 30 --max-model-ctx 0", "cpu_percent": 0, "memory_mb": 4.06}, {"pid": 55559, "name": "python3.13", "cmdline": "python huanhuan_train.py", "cpu_percent": 27.0, "memory_mb": 38.75}]}
{"timestamp": "2025-07-18T17:16:04.638382", "cpu": {"percent": 69.8, "count": 10, "freq": {"current": 3228, "min": 600, "max": 3228}}, "memory": {"total_gb": 32.0, "used_gb": 14.4, "available_gb": 4.13, "percent": 87.1}, "disk": {"total_gb": 926.35, "used_gb": 18.97, "free_gb": 628.79, "percent": 2.05}, "gpu": {"available": true, "type": "Apple M1 Pro", "utilization_percent": 11.99, "memory_used_mb": null, "memory_total_mb": null}, "training_processes": [{"pid": 9769, "name": "full-line-inference", "cmdline": "/Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/full-line-inference.zip_extracted/full-line-inference.app/Contents/MacOS/full-line-inference --model /Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/flcc.model --type llama --beam-size 2 --iterations-count 20 --context-ratio 0.5 --min-cached 5 --max-missing 30 --max-model-ctx 0", "cpu_percent": 0, "memory_mb": 4.22}, {"pid": 55559, "name": "python3.13", "cmdline": "python huanhuan_train.py", "cpu_percent": 21.0, "memory_mb": 43.5}]}
{"timestamp": "2025-07-18T17:16:13.713527", "cpu": {"percent": 59.7, "count": 10, "freq": {"current": 3228, "min": 600, "max": 3228}}, "memory": {"total_gb": 32.0, "used_gb": 15.86, "available_gb": 3.88, "percent": 87.9}, "disk": {"total_gb": 926.35, "used_gb": 18.97, "free_gb": 629.79, "percent": 2.05}, "gpu": {"available": true, "type": "Apple M1 Pro", "utilization_percent": 40.8, "memory_used_mb": null, "memory_total_mb": null}, "training_processes": [{"pid": 9769, "name": "full-line-inference", "cmdline": "/Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/full-line-inference.zip_extracted/full-line-inference.app/Contents/MacOS/full-line-inference --model /Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/flcc.model --type llama --beam-size 2 --iterations-count 20 --context-ratio 0.5 --min-cached 5 --max-missing 30 --max-model-ctx 0", "cpu_percent": 0, "memory_mb": 4.22}, {"pid": 55559, "name": "python3.13", "cmdline": "python huanhuan_train.py", "cpu_percent": 26.5, "memory_mb": 51.45}]}
{"timestamp": "2025-07-18T17:16:22.439567", "cpu": {"percent": 52.3, "count": 10, "freq": {"current": 3228, "min": 600, "max": 3228}}, "memory": {"total_gb": 32.0, "used_gb": 17.9, "available_gb": 3.36, "percent": 89.5}, "disk": {"total_gb": 926.35, "used_gb": 18.97, "free_gb": 628.79, "percent": 2.05}, "gpu": {"available": true, "type": "Apple M1 Pro", "utilization_percent": 14.46, "memory_used_mb": null, "memory_total_mb": null}, "training_processes": [{"pid": 9769, "name": "full-line-inference", "cmdline": "/Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/full-line-inference.zip_extracted/full-line-inference.app/Contents/MacOS/full-line-inference --model /Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/flcc.model --type llama --beam-size 2 --iterations-count 20 --context-ratio 0.5 --min-cached 5 --max-missing 30 --max-model-ctx 0", "cpu_percent": 0, "memory_mb": 4.22}, {"pid": 55559, "name": "python3.13", "cmdline": "python huanhuan_train.py", "cpu_percent": 25.5, "memory_mb": 44.02}]}
{"timestamp": "2025-07-18T17:16:32.654549", "cpu": {"percent": 88.4, "count": 10, "freq": {"current": 3228, "min": 600, "max": 3228}}, "memory": {"total_gb": 32.0, "used_gb": 12.78, "available_gb": 5.25, "percent": 83.6}, "disk": {"total_gb": 926.35, "used_gb": 18.97, "free_gb": 628.79, "percent": 2.05}, "gpu": {"available": true, "type": "Apple M1 Pro", "utilization_percent": 37.25, "memory_used_mb": null, "memory_total_mb": null}, "training_processes": [{"pid": 9769, "name": "full-line-inference", "cmdline": "/Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/full-line-inference.zip_extracted/full-line-inference.app/Contents/MacOS/full-line-inference --model /Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/flcc.model --type llama --beam-size 2 --iterations-count 20 --context-ratio 0.5 --min-cached 5 --max-missing 30 --max-model-ctx 0", "cpu_percent": 0, "memory_mb": 4.22}, {"pid": 55559, "name": "python3.13", "cmdline": "python huanhuan_train.py", "cpu_percent": 18.7, "memory_mb": 43.02}]}
{"timestamp": "2025-07-18T17:16:42.304639", "cpu": {"percent": 57.6, "count": 10, "freq": {"current": 3228, "min": 600, "max": 3228}}, "memory": {"total_gb": 32.0, "used_gb": 16.59, "available_gb": 3.65, "percent": 88.6}, "disk": {"total_gb": 926.35, "used_gb": 18.97, "free_gb": 628.79, "percent": 2.05}, "gpu": {"available": true, "type": "Apple M1 Pro", "utilization_percent": 11.29, "memory_used_mb": null, "memory_total_mb": null}, "training_processes": [{"pid": 9769, "name": "full-line-inference", "cmdline": "/Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/full-line-inference.zip_extracted/full-line-inference.app/Contents/MacOS/full-line-inference --model /Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/flcc.model --type llama --beam-size 2 --iterations-count 20 --context-ratio 0.5 --min-cached 5 --max-missing 30 --max-model-ctx 0", "cpu_percent": 0, "memory_mb": 4.27}, {"pid": 55559, "name": "python3.13", "cmdline": "python huanhuan_train.py", "cpu_percent": 27.1, "memory_mb": 46.59}]}
{"timestamp": "2025-07-18T17:16:50.523723", "cpu": {"percent": 61.8, "count": 10, "freq": {"current": 3228, "min": 600, "max": 3228}}, "memory": {"total_gb": 32.0, "used_gb": 13.05, "available_gb": 5.78, "percent": 81.9}, "disk": {"total_gb": 926.35, "used_gb": 18.97, "free_gb": 628.78, "percent": 2.05}, "gpu": {"available": true, "type": "Apple M1 Pro", "utilization_percent": 19.72, "memory_used_mb": null, "memory_total_mb": null}, "training_processes": [{"pid": 9769, "name": "full-line-inference", "cmdline": "/Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/full-line-inference.zip_extracted/full-line-inference.app/Contents/MacOS/full-line-inference --model /Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/flcc.model --type llama --beam-size 2 --iterations-count 20 --context-ratio 0.5 --min-cached 5 --max-missing 30 --max-model-ctx 0", "cpu_percent": 0, "memory_mb": 4.09}, {"pid": 55559, "name": "python3.13", "cmdline": "python huanhuan_train.py", "cpu_percent": 27.9, "memory_mb": 43.81}]}
{"timestamp": "2025-07-18T17:16:59.465742", "cpu": {"percent": 71.6, "count": 10, "freq": {"current": 3228, "min": 600, "max": 3228}}, "memory": {"total_gb": 32.0, "used_gb": 15.21, "available_gb": 6.08, "percent": 81.0}, "disk": {"total_gb": 926.35, "used_gb": 18.97, "free_gb": 628.78, "percent": 2.05}, "gpu": {"available": true, "type": "Apple M1 Pro", "utilization_percent": 25.27, "memory_used_mb": null, "memory_total_mb": null}, "training_processes": [{"pid": 9769, "name": "full-line-inference", "cmdline": "/Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/full-line-inference.zip_extracted/full-line-inference.app/Contents/MacOS/full-line-inference --model /Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/flcc.model --type llama --beam-size 2 --iterations-count 20 --context-ratio 0.5 --min-cached 5 --max-missing 30 --max-model-ctx 0", "cpu_percent": 0, "memory_mb": 4.06}, {"pid": 55559, "name": "python3.13", "cmdline": "python huanhuan_train.py", "cpu_percent": 23.8, "memory_mb": 37.41}]}
{"timestamp": "2025-07-18T17:17:07.515302", "cpu": {"percent": 33.6, "count": 10, "freq": {"current": 3228, "min": 600, "max": 3228}}, "memory": {"total_gb": 32.0, "used_gb": 19.51, "available_gb": 2.98, "percent": 90.7}, "disk": {"total_gb": 926.35, "used_gb": 18.97, "free_gb": 627.79, "percent": 2.05}, "gpu": {"available": true, "type": "Apple M1 Pro", "utilization_percent": 34.93, "memory_used_mb": null, "memory_total_mb": null}, "training_processes": [{"pid": 9769, "name": "full-line-inference", "cmdline": "/Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/full-line-inference.zip_extracted/full-line-inference.app/Contents/MacOS/full-line-inference --model /Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/flcc.model --type llama --beam-size 2 --iterations-count 20 --context-ratio 0.5 --min-cached 5 --max-missing 30 --max-model-ctx 0", "cpu_percent": 0, "memory_mb": 4.06}, {"pid": 55559, "name": "python3.13", "cmdline": "python huanhuan_train.py", "cpu_percent": 24.7, "memory_mb": 101.08}]}
{"timestamp": "2025-07-18T17:17:16.378250", "cpu": {"percent": 45.0, "count": 10, "freq": {"current": 3228, "min": 600, "max": 3228}}, "memory": {"total_gb": 32.0, "used_gb": 11.4, "available_gb": 11.6, "percent": 63.8}, "disk": {"total_gb": 926.35, "used_gb": 18.97, "free_gb": 627.75, "percent": 2.05}, "gpu": {"available": true, "type": "Apple M1 Pro", "utilization_percent": 12.59, "memory_used_mb": null, "memory_total_mb": null}, "training_processes": [{"pid": 9769, "name": "full-line-inference", "cmdline": "/Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/full-line-inference.zip_extracted/full-line-inference.app/Contents/MacOS/full-line-inference --model /Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/flcc.model --type llama --beam-size 2 --iterations-count 20 --context-ratio 0.5 --min-cached 5 --max-missing 30 --max-model-ctx 0", "cpu_percent": 0, "memory_mb": 4.28}]}
{"timestamp": "2025-07-18T17:17:24.390868", "cpu": {"percent": 50.2, "count": 10, "freq": {"current": 3228, "min": 600, "max": 3228}}, "memory": {"total_gb": 32.0, "used_gb": 12.73, "available_gb": 9.87, "percent": 69.2}, "disk": {"total_gb": 926.35, "used_gb": 18.97, "free_gb": 630.75, "percent": 2.05}, "gpu": {"available": true, "type": "Apple M1 Pro", "utilization_percent": 19.85, "memory_used_mb": null, "memory_total_mb": null}, "training_processes": [{"pid": 9769, "name": "full-line-inference", "cmdline": "/Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/full-line-inference.zip_extracted/full-line-inference.app/Contents/MacOS/full-line-inference --model /Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/flcc.model --type llama --beam-size 2 --iterations-count 20 --context-ratio 0.5 --min-cached 5 --max-missing 30 --max-model-ctx 0", "cpu_percent": 0, "memory_mb": 4.28}]}
{"timestamp": "2025-07-18T17:17:32.219386", "cpu": {"percent": 36.2, "count": 10, "freq": {"current": 3228, "min": 600, "max": 3228}}, "memory": {"total_gb": 32.0, "used_gb": 13.62, "available_gb": 9.01, "percent": 71.8}, "disk": {"total_gb": 926.35, "used_gb": 18.97, "free_gb": 633.74, "percent": 2.05}, "gpu": {"available": true, "type": "Apple M1 Pro", "utilization_percent": 4.69, "memory_used_mb": null, "memory_total_mb": null}, "training_processes": [{"pid": 9769, "name": "full-line-inference", "cmdline": "/Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/full-line-inference.zip_extracted/full-line-inference.app/Contents/MacOS/full-line-inference --model /Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/flcc.model --type llama --beam-size 2 --iterations-count 20 --context-ratio 0.5 --min-cached 5 --max-missing 30 --max-model-ctx 0", "cpu_percent": 0, "memory_mb": 4.28}]}
{"timestamp": "2025-07-18T17:17:40.218292", "cpu": {"percent": 56.8, "count": 10, "freq": {"current": 3228, "min": 600, "max": 3228}}, "memory": {"total_gb": 32.0, "used_gb": 13.33, "available_gb": 8.77, "percent": 72.6}, "disk": {"total_gb": 926.35, "used_gb": 18.97, "free_gb": 635.75, "percent": 2.05}, "gpu": {"available": true, "type": "Apple M1 Pro", "utilization_percent": 19.65, "memory_used_mb": null, "memory_total_mb": null}, "training_processes": [{"pid": 9769, "name": "full-line-inference", "cmdline": "/Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/full-line-inference.zip_extracted/full-line-inference.app/Contents/MacOS/full-line-inference --model /Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/flcc.model --type llama --beam-size 2 --iterations-count 20 --context-ratio 0.5 --min-cached 5 --max-missing 30 --max-model-ctx 0", "cpu_percent": 0, "memory_mb": 4.27}]}
{"timestamp": "2025-07-18T17:17:48.393401", "cpu": {"percent": 64.6, "count": 10, "freq": {"current": 3228, "min": 600, "max": 3228}}, "memory": {"total_gb": 32.0, "used_gb": 12.07, "available_gb": 7.4, "percent": 76.9}, "disk": {"total_gb": 926.35, "used_gb": 18.97, "free_gb": 636.74, "percent": 2.05}, "gpu": {"available": true, "type": "Apple M1 Pro", "utilization_percent": 3.72, "memory_used_mb": null, "memory_total_mb": null}, "training_processes": [{"pid": 9769, "name": "full-line-inference", "cmdline": "/Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/full-line-inference.zip_extracted/full-line-inference.app/Contents/MacOS/full-line-inference --model /Users/dapeng/Library/Caches/JetBrains/GoLand2025.1/full-line/models/046c5d78-720c-3ea8-8cbe-003e8e0ca270/flcc.model --type llama --beam-size 2 --iterations-count 20 --context-ratio 0.5 --min-cached 5 --max-missing 30 --max-model-ctx 0", "cpu_percent": 0, "memory_mb": 4.95}]}
{"timestamp": "2025-07-25T07:34:03.349656", "cpu": {"percent": 23.8, "count": 10, "freq": {"current": 3228, "min": 600, "max": 3228}}, "memory": {"total_gb": 32.0, "used_gb": 10.71, "available_gb": 5.24, "percent": 83.6}, "disk": {"total_gb": 926.35, "used_gb": 18.97, "free_gb": 603.02, "percent": 2.05}, "gpu": {"available": true, "type": "Apple M1 Pro", "utilization_percent": 4.32, "memory_used_mb": null, "memory_total_mb": null}, "training_processes": []}
{"timestamp": "2025-07-25T07:34:15.697334", "cpu": {"percent": 22.7, "count": 10, "freq": {"current": 3228, "min": 600, "max": 3228}}, "memory": {"total_gb": 32.0, "used_gb": 10.66, "available_gb": 5.26, "percent": 83.6}, "disk": {"total_gb": 926.35, "used_gb": 18.97, "free_gb": 603.02, "percent": 2.05}, "gpu": {"available": true, "type": "Apple M1 Pro", "utilization_percent": 6.19, "memory_used_mb": null, "memory_total_mb": null}, "training_processes": []}
{"timestamp": "2025-07-25T07:34:40.212774", "cpu": {"percent": 63.9, "count": 10, "freq": {"current": 3228, "min": 600, "max": 3228}}, "memory": {"total_gb": 32.0, "used_gb": 18.32, "available_gb": 2.54, "percent": 92.1}, "disk": {"total_gb": 926.35, "used_gb": 18.97, "free_gb": 594.02, "percent": 2.05}, "gpu": {"available": true, "type": "Apple M1 Pro", "utilization_percent": 93.67, "memory_used_mb": null, "memory_total_mb": null}, "training_processes": [{"pid": 17218, "name": "python3.13", "cmdline": "python huanhuan_train.py", "cpu_percent": 23.2, "memory_mb": 175.72}]}
{"timestamp": "2025-07-25T07:34:48.726301", "cpu": {"percent": 57.0, "count": 10, "freq": {"current": 3228, "min": 600, "max": 3228}}, "memory": {"total_gb": 32.0, "used_gb": 23.19, "available_gb": 1.94, "percent": 93.9}, "disk": {"total_gb": 926.35, "used_gb": 18.97, "free_gb": 591.02, "percent": 2.05}, "gpu": {"available": true, "type": "Apple M1 Pro", "utilization_percent": 99.48, "memory_used_mb": null, "memory_total_mb": null}, "training_processes": [{"pid": 17218, "name": "python3.13", "cmdline": "python huanhuan_train.py", "cpu_percent": 37.8, "memory_mb": 198.58}]}
{"timestamp": "2025-07-25T07:34:57.583638", "cpu": {"percent": 51.7, "count": 10, "freq": {"current": 3228, "min": 600, "max": 3228}}, "memory": {"total_gb": 32.0, "used_gb": 24.0, "available_gb": 2.25, "percent": 93.0}, "disk": {"total_gb": 926.35, "used_gb": 18.97, "free_gb": 590.02, "percent": 2.05}, "gpu": {"available": true, "type": "Apple M1 Pro", "utilization_percent": 91.5, "memory_used_mb": null, "memory_total_mb": null}, "training_processes": [{"pid": 17218, "name": "python3.13", "cmdline": "python huanhuan_train.py", "cpu_percent": 35.8, "memory_mb": 132.95}]}
