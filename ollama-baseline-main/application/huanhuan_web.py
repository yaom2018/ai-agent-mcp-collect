#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç”„å¬›è§’è‰²Webå¯¹è¯ç•Œé¢

åŸºäºStreamlitçš„ç”„å¬›è§’è‰²å¯¹è¯Webåº”ç”¨
å‚è€ƒ: https://github.com/KMnO4-zx/huanhuan-chat

ä½¿ç”¨æ–¹æ³•:
    streamlit run application/huanhuan_web.py
    streamlit run application/huanhuan_web.py --server.port 8501
"""

import os
import sys
import json
import requests
import streamlit as st
from pathlib import Path
from typing import List, Dict
import time
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="Chat-å¬›å¬› - ç”„å¬›ä¼ è§’è‰²å¯¹è¯",
    page_icon="ğŸ‘¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

class HuanHuanWebApp:
    """
    ç”„å¬›Webåº”ç”¨
    """
    
    def __init__(self):
        self.ollama_host = "http://localhost:11434"
        self.model_name = "huanhuan-qwen"
        
        # åˆå§‹åŒ–session state
        self.init_session_state()
    
    def init_session_state(self):
        """
        åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
        """
        # å¯¹è¯å†å²
        if "messages" not in st.session_state:
            st.session_state.messages = []
        
        # Ollamaè¿æ¥çŠ¶æ€
        if "ollama_connected" not in st.session_state:
            st.session_state.ollama_connected = False
        
        # å¯ç”¨æ¨¡å‹åˆ—è¡¨
        if "available_models" not in st.session_state:
            st.session_state.available_models = []
        
        # å½“å‰é€‰æ‹©çš„æ¨¡å‹
        if "selected_model" not in st.session_state:
            st.session_state.selected_model = None
        
        # ç”Ÿæˆå‚æ•°
        if "temperature" not in st.session_state:
            st.session_state.temperature = 0.7
        if "top_p" not in st.session_state:
            st.session_state.top_p = 0.9
        if "top_k" not in st.session_state:
            st.session_state.top_k = 40
        if "max_tokens" not in st.session_state:
            st.session_state.max_tokens = 256
        
        # å¯¹è¯å†å²è®°å½•
        if 'chat_history' not in st.session_state:
            st.session_state.chat_history = []
    
    def check_ollama_connection(self) -> bool:
        """
        æ£€æŸ¥OllamaæœåŠ¡è¿æ¥çŠ¶æ€
        """
        try:
            response = requests.get(f"{self.ollama_host}/api/tags", timeout=5)
            if response.status_code == 200:
                st.session_state.ollama_connected = True
                return True
        except requests.exceptions.RequestException:
            pass
        
        st.session_state.ollama_connected = False
        return False
    
    def get_available_models(self) -> List[str]:
        """
        è·å–å¯ç”¨çš„æ¨¡å‹åˆ—è¡¨
        """
        if not self.check_ollama_connection():
            return []
        
        try:
            response = requests.get(f"{self.ollama_host}/api/tags")
            if response.status_code == 200:
                data = response.json()
                models = [model['name'] for model in data.get('models', [])]
                st.session_state.available_models = models
                return models
        except Exception as e:
            st.error(f"è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥: {e}")
        
        return []
    
    def stream_chat(self, messages, model):
        """
        æµå¼å¯¹è¯ç”Ÿæˆ
        """
        url = f"{self.ollama_host}/api/chat"
        
        payload = {
            "model": model,
            "messages": messages,
            "stream": True,
            "options": {
                "temperature": st.session_state.temperature,
                "top_p": st.session_state.top_p,
                "top_k": st.session_state.top_k
            }
        }
        
        try:
            response = requests.post(url, json=payload, stream=True, timeout=60)
            response.raise_for_status()
            
            for line in response.iter_lines():
                if line:
                    try:
                        data = json.loads(line.decode('utf-8'))
                        if 'message' in data and 'content' in data['message']:
                            yield data['message']['content']
                        
                        if data.get('done', False):
                            break
                    except json.JSONDecodeError:
                        continue
                        
        except requests.exceptions.RequestException as e:
            yield f"è¿æ¥é”™è¯¯: {e}"
        except Exception as e:
            yield f"æœªçŸ¥é”™è¯¯: {e}"
    
    def render_sidebar(self):
        """
        æ¸²æŸ“ä¾§è¾¹æ 
        """
        with st.sidebar:
            st.title("âš™ï¸ è®¾ç½®")
            
            # è¿æ¥çŠ¶æ€
            if self.check_ollama_connection():
                st.success("ğŸŸ¢ OllamaæœåŠ¡å·²è¿æ¥")
            else:
                st.error("ğŸ”´ OllamaæœåŠ¡æœªè¿æ¥")
                st.info("è¯·ç¡®ä¿OllamaæœåŠ¡æ­£åœ¨è¿è¡Œ")
            
            st.divider()
            
            # æ¨¡å‹é€‰æ‹©
            st.subheader("ğŸ¤– æ¨¡å‹è®¾ç½®")
            available_models = self.get_available_models()
            
            if available_models:
                if self.model_name in available_models:
                    default_index = available_models.index(self.model_name)
                else:
                    default_index = 0
                
                selected_model = st.selectbox(
                    "é€‰æ‹©æ¨¡å‹",
                    available_models,
                    index=default_index
                )
                st.session_state.selected_model = selected_model
                self.model_name = selected_model
            else:
                st.warning("æœªæ‰¾åˆ°å¯ç”¨æ¨¡å‹")
                st.info("è¯·å…ˆéƒ¨ç½²ç”„å¬›æ¨¡å‹")
            
            st.divider()
            
            # å‚æ•°è°ƒèŠ‚
            st.subheader("ğŸ›ï¸ ç”Ÿæˆå‚æ•°")
            
            st.session_state.temperature = st.slider(
                "Temperature (åˆ›é€ æ€§)",
                min_value=0.1,
                max_value=2.0,
                value=st.session_state.temperature,
                step=0.1,
                help="æ§åˆ¶å›ç­”çš„éšæœºæ€§ï¼Œå€¼è¶Šé«˜è¶Šæœ‰åˆ›é€ æ€§"
            )
            
            st.session_state.top_p = st.slider(
                "Top P (å¤šæ ·æ€§)",
                min_value=0.1,
                max_value=1.0,
                value=st.session_state.top_p,
                step=0.1,
                help="æ§åˆ¶è¯æ±‡é€‰æ‹©çš„å¤šæ ·æ€§"
            )
            
            st.session_state.top_k = st.slider(
                "Top K (è¯æ±‡èŒƒå›´)",
                min_value=1,
                max_value=100,
                value=st.session_state.top_k,
                step=1,
                help="é™åˆ¶æ¯æ­¥é€‰æ‹©çš„è¯æ±‡æ•°é‡"
            )
            
            st.session_state.max_tokens = st.slider(
                "Max Tokens (å›ç­”é•¿åº¦)",
                min_value=50,
                max_value=500,
                value=st.session_state.max_tokens,
                step=10,
                help="æ§åˆ¶å›ç­”çš„æœ€å¤§é•¿åº¦"
            )
            
            st.divider()
            
            # åŠŸèƒ½æŒ‰é’®
            st.subheader("ğŸ› ï¸ åŠŸèƒ½")
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                if st.button("ğŸ—‘ï¸ æ¸…ç©ºå¯¹è¯", use_container_width=True):
                    st.session_state.messages = []
                    st.session_state.chat_history = []
                    st.rerun()
            
            with col2:
                if st.button("ğŸ’¾ ä¿å­˜å¯¹è¯", use_container_width=True):
                    if st.session_state.chat_history:
                        self.save_chat_history()
                        st.success("å¯¹è¯å·²ä¿å­˜ï¼")
                    else:
                        st.warning("æ²¡æœ‰å¯¹è¯å†…å®¹å¯ä¿å­˜")
            
            with col3:
                if st.button("ğŸ“‚ åŠ è½½å¯¹è¯", use_container_width=True):
                    self.load_chat_history()
    
    def render_main_content(self):
        """
        æ¸²æŸ“ä¸»è¦å†…å®¹
        """
        # æ ‡é¢˜å’Œä»‹ç»
        st.title("ğŸ‘¸ Chat-å¬›å¬›")
        st.markdown("""
        æ¬¢è¿æ¥åˆ°ç”„å¬›ä¼ è§’è‰²å¯¹è¯ç³»ç»Ÿï¼æˆ‘æ˜¯ç”„å¬›ï¼Œå¤§ç†å¯ºå°‘å¿ç”„è¿œé“ä¹‹å¥³ã€‚
        è‡£å¦¾æ„¿ä¸æ‚¨ç•…è°ˆå®«å»·ç”Ÿæ´»ã€è¯—è¯æ­Œèµ‹ï¼Œåˆ†äº«äººç”Ÿæ„Ÿæ‚Ÿã€‚
        """)
        
        # è§’è‰²ä¿¡æ¯å¡ç‰‡
        with st.expander("ğŸ“– è§’è‰²ä¿¡æ¯", expanded=False):
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("""
                **åŸºæœ¬ä¿¡æ¯**
                - å§“åï¼šç”„å¬›ï¼ˆç”„ç‰å¬›ï¼‰
                - èº«ä»½ï¼šç†¹è´µå¦ƒ
                - å‡ºèº«ï¼šå¤§ç†å¯ºå°‘å¿ç”„è¿œé“ä¹‹å¥³
                - ç‰¹é•¿ï¼šè¯—è¯æ­Œèµ‹ã€ç´æ£‹ä¹¦ç”»
                """)
            
            with col2:
                st.markdown("""
                **æ€§æ ¼ç‰¹ç‚¹**
                - èªæ…§æœºæ™ºï¼Œå–„äºåº”å˜
                - æ¸©å©‰è´¤æ·‘ï¼ŒçŸ¥ä¹¦è¾¾ç†
                - åšéŸ§ä¸æ‹”ï¼Œé‡æƒ…é‡ä¹‰
                - è¯­è¨€å…¸é›…ï¼Œè°¦é€Šæœ‰ç¤¼
                """)
        
        # ç¤ºä¾‹é—®é¢˜
        st.subheader("ğŸ’¡ ç¤ºä¾‹é—®é¢˜")
        example_questions = [
            "ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±",
            "ä½ è§‰å¾—å®«å»·ç”Ÿæ´»å¦‚ä½•ï¼Ÿ",
            "å¦‚ä½•çœ‹å¾…å‹æƒ…ï¼Ÿ",
            "èƒ½ä¸ºæˆ‘ä½œä¸€é¦–è¯—å—ï¼Ÿ",
            "ç»™åäººä¸€äº›äººç”Ÿå»ºè®®",
            "ä½ æœ€å–œæ¬¢ä»€ä¹ˆï¼Ÿ"
        ]
        
        cols = st.columns(3)
        for i, question in enumerate(example_questions):
            with cols[i % 3]:
                if st.button(question, key=f"example_{i}", use_container_width=True):
                    st.session_state.current_question = question
        
        st.divider()
        
        # å¯¹è¯å†å²
        st.subheader("ğŸ’¬ å¯¹è¯å†å²")
        
        # æ˜¾ç¤ºå¯¹è¯æ¶ˆæ¯
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])
        
        # å¤„ç†ç¤ºä¾‹é—®é¢˜
        if hasattr(st.session_state, 'current_question'):
            user_input = st.session_state.current_question
            delattr(st.session_state, 'current_question')
        else:
            user_input = None
        
        # èŠå¤©è¾“å…¥
        if prompt := st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜...") or user_input:
            # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
            st.session_state.messages.append({"role": "user", "content": prompt})
            
            with st.chat_message("user"):
                st.markdown(prompt)
            
            # ç”Ÿæˆå›å¤
            with st.chat_message("assistant"):
                with st.spinner("ç”„å¬›æ­£åœ¨æ€è€ƒ..."):
                    # ä½¿ç”¨æµå¼ç”Ÿæˆ
                    response_placeholder = st.empty()
                    full_response = ""
                    
                    # æ„å»ºæ¶ˆæ¯å†å²
                    messages = []
                    for msg in st.session_state.messages:
                        messages.append({
                            "role": msg["role"],
                            "content": msg["content"]
                        })
                    
                    for chunk in self.stream_chat(messages, st.session_state.selected_model):
                        full_response += chunk
                        response_placeholder.markdown(full_response + "â–Œ")
                    
                    response_placeholder.markdown(full_response)
            
            # æ·»åŠ åŠ©æ‰‹æ¶ˆæ¯
            st.session_state.messages.append({"role": "assistant", "content": full_response})
            
            # ä¿å­˜åˆ°å†å²è®°å½•
            st.session_state.chat_history.append({
                "timestamp": datetime.now().isoformat(),
                "user": prompt,
                "assistant": full_response,
                "params": {
                    "temperature": st.session_state.temperature,
                    "top_p": st.session_state.top_p,
                    "top_k": st.session_state.top_k,
                    "max_tokens": st.session_state.max_tokens
                }
            })
    
    def save_chat_history(self):
        """
        ä¿å­˜å¯¹è¯å†å²
        """
        if not st.session_state.chat_history:
            return
        
        # åˆ›å»ºä¿å­˜ç›®å½•
        save_dir = Path("application/chat_history")
        save_dir.mkdir(parents=True, exist_ok=True)
        
        # ç”Ÿæˆæ–‡ä»¶å
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"huanhuan_chat_{timestamp}.json"
        filepath = save_dir / filename
        
        # ä¿å­˜æ•°æ®
        save_data = {
            "timestamp": timestamp,
            "chat_history": st.session_state.chat_history,
            "model_params": {
                "selected_model": st.session_state.selected_model,
                "temperature": st.session_state.temperature,
                "top_p": st.session_state.top_p,
                "top_k": st.session_state.top_k,
                "max_tokens": st.session_state.max_tokens
            }
        }
        
        try:
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(save_data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            st.error(f"ä¿å­˜å¤±è´¥: {e}")
    
    def load_chat_history(self):
        """
        åŠ è½½å¯¹è¯å†å²
        """
        save_dir = Path("application/chat_history")
        if not save_dir.exists():
            st.warning("æ²¡æœ‰æ‰¾åˆ°å†å²å¯¹è¯æ–‡ä»¶")
            return
        
        # è·å–æ‰€æœ‰å†å²æ–‡ä»¶
        history_files = list(save_dir.glob("*.json"))
        if not history_files:
            st.warning("æ²¡æœ‰æ‰¾åˆ°å†å²å¯¹è¯æ–‡ä»¶")
            return
        
        # é€‰æ‹©æ–‡ä»¶
        file_options = {f.name: f for f in sorted(history_files, reverse=True)}
        selected_file = st.selectbox(
            "é€‰æ‹©è¦åŠ è½½çš„å¯¹è¯:",
            options=list(file_options.keys())
        )
        
        if st.button("åŠ è½½é€‰ä¸­çš„å¯¹è¯"):
            try:
                with open(file_options[selected_file], 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                st.session_state.chat_history = data.get('chat_history', [])
                st.session_state.messages = []
                
                # é‡å»ºmessagesæ ¼å¼
                for chat in st.session_state.chat_history:
                    st.session_state.messages.append({"role": "user", "content": chat["user"]})
                    st.session_state.messages.append({"role": "assistant", "content": chat["assistant"]})
                
                # åŠ è½½æ¨¡å‹å‚æ•°
                if 'model_params' in data:
                    params = data['model_params']
                    if 'selected_model' in params:
                        st.session_state.selected_model = params['selected_model']
                    if 'temperature' in params:
                        st.session_state.temperature = params['temperature']
                    if 'top_p' in params:
                        st.session_state.top_p = params['top_p']
                    if 'top_k' in params:
                        st.session_state.top_k = params['top_k']
                    if 'max_tokens' in params:
                        st.session_state.max_tokens = params['max_tokens']
                
                st.success(f"å·²åŠ è½½å¯¹è¯: {selected_file}")
                st.rerun()
            except Exception as e:
                st.error(f"åŠ è½½å¤±è´¥: {e}")
    
    def get_history_files(self):
        """
        è·å–å†å²æ–‡ä»¶åˆ—è¡¨
        """
        save_dir = Path("application/chat_history")
        if not save_dir.exists():
            return []
        
        history_files = list(save_dir.glob("*.json"))
        return sorted([f.name for f in history_files], reverse=True)
    
    def render_footer(self):
        """
        æ¸²æŸ“é¡µè„š
        """
        st.divider()
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.markdown("**ğŸ“Š ç»Ÿè®¡ä¿¡æ¯**")
            st.metric("å¯¹è¯è½®æ•°", len(st.session_state.messages) // 2)
        
        with col2:
            st.markdown("**ğŸ”§ æŠ€æœ¯æ ˆ**")
            st.markdown("Streamlit + Ollama + LoRA")
        
        with col3:
            st.markdown("**ğŸ“š å‚è€ƒé¡¹ç›®**")
            st.markdown("[huanhuan-chat](https://github.com/KMnO4-zx/huanhuan-chat)")
    
    def run(self):
        """
        è¿è¡Œåº”ç”¨ä¸»æ–¹æ³•
        """
        # æ¸²æŸ“ä¾§è¾¹æ 
        self.render_sidebar()
        
        # æ¸²æŸ“ä¸»è¦å†…å®¹
        self.render_main_content()
        
        # æ¸²æŸ“é¡µè„š
        self.render_footer()

def main():
    """
    ä¸»å‡½æ•°
    """
    # è‡ªå®šä¹‰CSS
    st.markdown("""
    <style>
    .stApp {
        background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
    }
    
    .stChatMessage {
        background-color: rgba(255, 255, 255, 0.8);
        border-radius: 10px;
        padding: 10px;
        margin: 5px 0;
    }
    
    .stButton > button {
        border-radius: 20px;
        border: none;
        background: linear-gradient(45deg, #667eea 0%, #764ba2 100%);
        color: white;
    }
    
    .stButton > button:hover {
        background: linear-gradient(45deg, #764ba2 0%, #667eea 100%);
        transform: translateY(-2px);
        box-shadow: 0 4px 8px rgba(0,0,0,0.2);
    }
    </style>
    """, unsafe_allow_html=True)
    
    # åˆ›å»ºå¹¶è¿è¡Œåº”ç”¨
    app = HuanHuanWebApp()
    app.run()

if __name__ == "__main__":
    main()